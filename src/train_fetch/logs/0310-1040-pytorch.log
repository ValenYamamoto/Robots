epoch: 0, step: 0
	action: tensor([[ 3.2556, -1.3560, -2.9524, -0.7036,  0.1053,  0.1142,  0.9904]],
       dtype=torch.float64)
	q_value: tensor([[0.1240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.8700141906738281
epoch: 0, step: 1
	action: tensor([[ 0.5239,  0.2221,  1.5330, -0.6811,  2.0658, -2.6676,  0.8294]],
       dtype=torch.float64)
	q_value: tensor([[0.1241]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.8914675059560813, distance: 0.3769958633040482 entropy 1.8700141906738281
LOSS epoch 0 actor 441.3059170683733 critic 1256.6038453734075 
epoch: 1, step: 0
	action: tensor([[-1.7237,  1.1112,  2.1356, -2.8620, -1.4035, -0.2144,  2.5126]],
       dtype=torch.float64)
	q_value: tensor([[-0.0178]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.8700141906738281
epoch: 1, step: 1
	action: tensor([[ 0.2000, -0.4899, -2.6205, -2.3667, -1.9612,  1.1598, -2.4776]],
       dtype=torch.float64)
	q_value: tensor([[-0.1249]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.6811114471401374, distance: 0.6462136956774784 entropy 1.8700141906738281
LOSS epoch 1 actor 437.80868708294514 critic 1249.3426104362259 
epoch: 2, step: 0
	action: tensor([[ 1.8667, -1.3674, -0.5805, -1.0646, -0.9936, -1.3565,  3.1738]],
       dtype=torch.float64)
	q_value: tensor([[-0.4386]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.7646539211273193
epoch: 2, step: 1
	action: tensor([[-1.3872,  0.0061,  1.5997,  0.8099, -0.9400, -0.7654,  1.4516]],
       dtype=torch.float64)
	q_value: tensor([[-0.3066]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -1.057872187796379, distance: 1.6415945141730726 entropy 1.7646539211273193
LOSS epoch 2 actor 437.78235823588744 critic 1228.7236632944193 
epoch: 3, step: 0
	action: tensor([[ 0.0778,  0.7156,  1.1862,  0.7911, -1.6625, -3.0662,  0.6747]],
       dtype=torch.float64)
	q_value: tensor([[-0.3560]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.7646539211273193
