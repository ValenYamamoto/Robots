epoch: 0, step: 0
	action: tensor([[-3.2574, -2.3216, -0.7756, -0.2967, -0.5840, -1.2311,  0.8941]],
       dtype=torch.float64)
	q_value: tensor([[-0.4798]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1231809015084686
epoch: 0, step: 1
	action: tensor([[-3.4428, -1.9550,  0.0257,  0.5346, -1.2091,  0.8218,  0.4347]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 2
	action: tensor([[-2.8550, -0.1428, -0.5080,  1.6675, -2.2052, -0.2641,  0.3655]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 3
	action: tensor([[-3.4042, -2.1289,  0.4938,  0.4278, -1.7041,  1.4123,  0.1552]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 4
	action: tensor([[-2.6344, -1.9002, -1.7757, -0.7915, -0.9300, -1.3120,  2.8825]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 5
	action: tensor([[-3.8931, -2.2622, -0.6694, -0.6152, -1.0099,  1.5215,  0.0974]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 6
	action: tensor([[-2.6086, -1.9353, -0.4769,  0.9436, -1.6168, -0.9279,  1.6674]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 7
	action: tensor([[-3.1833, -1.4830,  0.0117,  0.1339, -0.8091,  1.7143,  2.4943]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 8
	action: tensor([[-3.9274, -1.5352, -0.5341,  0.3069, -2.2343,  2.4123,  0.7975]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 9
	action: tensor([[-3.2584, -1.2495,  0.1249,  0.9904, -1.7227,  0.1122, -1.6936]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 10
	action: tensor([[-1.7945, -1.2350,  0.5262, -0.0610, -1.2375,  2.2292,  0.5042]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 11
	action: tensor([[-3.8338, -2.0904,  0.0597, -0.0990, -2.0537,  2.6635,  0.2546]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 12
	action: tensor([[-4.0195, -2.0582, -0.1796,  0.1808, -1.5289,  1.2211,  1.6870]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 13
	action: tensor([[-2.6588, -2.3572, -0.1439,  0.3484, -1.3560, -1.6299,  1.5005]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 14
	action: tensor([[-1.8313, -2.5052,  0.0452,  0.6505, -1.5150,  2.3542, -0.3765]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 15
	action: tensor([[-2.4217, -2.0573,  0.0480, -0.1884, -0.8983,  0.9770,  0.0226]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 16
	action: tensor([[-3.2638, -2.2100, -0.4576,  1.0219, -0.5762,  2.5796, -0.4372]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 17
	action: tensor([[-4.0226, -2.0125, -0.0359,  1.1698, -1.0975,  2.0594,  0.7610]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 18
	action: tensor([[-2.4636, -1.9055, -1.2747,  1.7834, -1.1507,  0.7505,  1.7829]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 19
	action: tensor([[-2.9982, -1.2523, -0.6491,  0.6377, -2.2791, -2.2180,  1.2579]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 20
	action: tensor([[-3.8532, -2.8519,  0.3352, -1.3709, -1.0223,  0.9633,  0.6952]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 21
	action: tensor([[-2.6022, -1.6905, -1.0020,  1.8719, -1.4740,  2.4157,  1.2640]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 22
	action: tensor([[-4.1856, -2.5527,  0.8215, -2.3173, -1.2530, -1.5009,  1.4525]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 23
	action: tensor([[-2.8010, -1.4960,  0.1239,  3.3602, -0.9928,  0.3555, -0.6182]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 24
	action: tensor([[-2.9972, -2.7371, -0.8247, -0.6780, -0.8963,  0.9689,  3.7457]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 25
	action: tensor([[-3.7297, -1.9819,  0.0273,  0.3201, -1.1160, -0.1695,  1.0846]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 26
	action: tensor([[-3.7606, -2.3110, -0.5398,  0.4804, -1.2059, -1.4260,  0.5946]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 27
	action: tensor([[-3.3270, -2.1930, -0.0906,  0.9333, -1.1402, -0.5085,  1.1386]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 28
	action: tensor([[-2.8096, -1.6603, -0.0352,  1.1279, -1.3975,  0.7195,  1.5800]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 29
	action: tensor([[-3.0706, -1.1804, -0.1947, -0.6236, -1.2570, -1.0040,  0.0563]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 30
	action: tensor([[-4.6710e+00,  7.8346e-02,  3.0207e-01,  2.0381e-01, -1.7152e+00,
          1.7732e+00, -1.7151e-03]], dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 31
	action: tensor([[-2.7787, -2.3564, -0.5666, -1.0175, -1.6679,  0.7968, -2.0678]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 32
	action: tensor([[-3.3925, -1.7055, -0.3725, -0.0942, -1.7267,  0.8439, -0.0724]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 33
	action: tensor([[-3.7483, -1.5616, -0.6829,  0.4825, -1.2345,  3.4970,  0.0860]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 34
	action: tensor([[-2.6606, -0.7573,  0.0616,  1.1882, -1.1930,  0.9267,  0.9482]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 35
	action: tensor([[-3.1435, -3.5885, -0.0177, -1.1714, -0.6254, -1.5073, -0.7589]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 36
	action: tensor([[-2.8428, -2.8061, -0.0603,  0.0130, -0.9653,  0.0993, -0.4609]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 37
	action: tensor([[-3.5361, -1.2385, -0.1063,  1.6300, -0.9717,  0.4700,  1.6356]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 38
	action: tensor([[-3.2316, -2.2044,  0.4727, -0.9993, -0.7012,  1.3779,  1.9663]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 39
	action: tensor([[-2.2379, -2.6931, -0.5364,  2.3656, -1.5653,  0.1285,  0.0686]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 40
	action: tensor([[-2.2882, -2.4295,  0.2853,  0.7632, -2.0487,  1.4096, -0.6342]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 41
	action: tensor([[-2.8849, -2.3049,  0.0573,  2.4485, -0.8498,  0.8641,  1.4441]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 42
	action: tensor([[-3.0249,  0.7925, -0.0600,  1.2982, -2.0350, -0.7758,  0.5748]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 43
	action: tensor([[-3.5304, -2.4722, -0.7832,  1.3981, -1.4591,  0.4574, -0.7890]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 44
	action: tensor([[-3.7579e+00, -1.4428e+00,  3.3151e-04,  1.8696e+00, -3.7797e-01,
          2.0532e+00,  2.2219e+00]], dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 45
	action: tensor([[-3.3320, -0.8344, -0.2504,  2.7021, -1.1723,  0.3020,  0.3474]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 46
	action: tensor([[-3.9926, -3.0331,  0.4431,  1.1014, -1.5703, -1.7961,  1.6362]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 47
	action: tensor([[-3.6926, -2.2576, -0.5550,  0.5907, -1.3461,  3.0436, -0.1515]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 48
	action: tensor([[-2.6838, -4.0167,  0.0581,  1.6019, -1.6152,  1.0421,  1.0468]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 49
	action: tensor([[-2.9470, -1.5511, -0.0718, -0.3098, -0.7796,  0.6642,  0.3789]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 50
	action: tensor([[-3.3858, -1.7901,  0.2382,  1.0593, -1.0963,  0.4979,  0.4532]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 51
	action: tensor([[-3.0744, -1.9429, -0.2403,  2.1635, -0.9662,  1.0563,  0.2581]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 52
	action: tensor([[-3.0198, -1.6406, -0.2782,  3.2663, -2.0463,  2.8034,  2.5304]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 53
	action: tensor([[-2.5982, -1.9890, -0.0495,  0.3617, -1.2900, -0.3087,  0.7808]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 54
	action: tensor([[-2.4875, -1.4198, -0.3294, -0.2373, -0.8289,  1.2930, -0.2561]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 55
	action: tensor([[-3.3273, -1.6528, -0.2786,  0.4377, -0.9899, -0.6538,  1.1196]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 56
	action: tensor([[-2.6114, -1.0108, -1.2744,  2.4561, -1.1158,  1.0274,  1.4500]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 57
	action: tensor([[-4.3882, -1.7883, -0.4088,  2.3762, -1.2360, -0.1543,  0.5398]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 58
	action: tensor([[-3.2856, -2.4877, -0.3505,  2.3954, -0.5416, -1.1478,  0.8651]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 59
	action: tensor([[-3.5178, -0.8768, -0.5113,  1.6938, -1.0890,  1.1125,  0.3003]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 60
	action: tensor([[-4.0179, -0.6129, -0.1662,  0.1392, -0.6416,  0.6560,  2.0606]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 61
	action: tensor([[-3.0081, -3.2478,  0.3118,  1.9581, -0.8311,  0.1886, -0.8269]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 62
	action: tensor([[-3.1657, -1.4347, -0.0332,  1.0973, -1.3623, -0.4183,  0.9915]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 63
	action: tensor([[-3.3373, -0.0740, -0.8250,  0.5492, -0.6493, -1.7600,  0.2934]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 64
	action: tensor([[-1.7517, -1.8470,  0.4457, -0.7775, -0.4354,  2.1259,  1.2297]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 65
	action: tensor([[-2.8634, -1.6332, -0.5299,  0.2499, -1.4973,  1.4484, -1.1383]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 66
	action: tensor([[-3.2082, -1.3879, -0.4212, -1.8119, -1.1806,  0.5033, -0.3730]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 67
	action: tensor([[-3.3826, -2.9507,  0.1531,  0.3740, -1.3576, -0.1598,  0.1040]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 68
	action: tensor([[-4.4157, -0.8962, -0.7521,  0.8356, -1.1775, -0.5594,  0.8356]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 69
	action: tensor([[-3.7806, -2.4241,  0.2928,  0.8959, -1.1453,  0.3006, -1.6970]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 70
	action: tensor([[-3.4203, -1.5204,  1.0570,  0.8237, -1.0033, -1.3134, -0.7958]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 71
	action: tensor([[-2.4622, -1.8329, -0.5698,  0.9513, -0.5371,  1.7281, -0.5432]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 72
	action: tensor([[-2.9471, -2.8471, -0.4026,  0.7279, -1.5759,  0.5759, -0.1511]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 73
	action: tensor([[-4.4423, -1.4298, -1.1356,  1.4403, -1.8477, -0.3796,  0.7447]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 74
	action: tensor([[-3.9305, -2.5996, -0.2791,  1.1426, -0.6417, -2.1482,  0.2307]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 75
	action: tensor([[-3.8364, -2.4314, -0.3059,  1.2928, -1.1465,  2.4982,  2.3914]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 76
	action: tensor([[-2.8745, -1.1904, -0.2419,  0.5222, -0.6422, -1.0532,  1.6311]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 77
	action: tensor([[-2.4686, -2.9337, -0.6727, -0.9971, -1.1648, -0.5392, -0.7548]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 78
	action: tensor([[-2.9022, -2.3131, -0.1190, -0.0547, -1.3532,  2.0854,  0.7845]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 79
	action: tensor([[-3.7821, -1.9391, -0.3117,  1.0494, -1.0231,  0.1923,  2.4517]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 80
	action: tensor([[-2.9765, -0.7506, -0.7949, -0.1755, -1.5870,  0.3342,  1.6718]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 81
	action: tensor([[-3.8607, -0.6580, -0.4379,  2.5151, -1.0140,  0.6085, -1.5681]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 82
	action: tensor([[-2.8967, -1.6823, -0.6393,  0.3790, -0.5496, -1.8573,  1.0702]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 83
	action: tensor([[-2.8404, -1.4955, -0.3704,  2.7472, -1.8026,  0.6293,  0.2591]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 84
	action: tensor([[-3.5753, -0.7047, -1.5735,  0.6809, -1.3787, -0.1428, -0.0873]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 85
	action: tensor([[-3.4476, -1.9072, -0.6289,  0.7833, -1.5219,  1.8290,  0.9580]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 86
	action: tensor([[-2.3582, -1.3742, -0.3521,  1.4663, -0.9281,  1.0423,  0.2295]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 87
	action: tensor([[-4.6726, -1.8840, -0.2887, -0.4614, -1.5605,  1.1412,  0.9627]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 88
	action: tensor([[-3.1976, -1.6690, -0.7056,  2.7720, -0.9314,  1.4806,  1.9963]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 89
	action: tensor([[-3.0851, -1.3269, -1.4207, -0.3215, -0.8623,  1.2613,  1.2313]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 90
	action: tensor([[-2.7624, -2.0483, -0.7848, -0.0657, -1.1949, -2.1834,  0.4502]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 91
	action: tensor([[-3.2579, -2.8335, -0.2268,  2.2817, -1.0044,  1.7295,  0.2790]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 92
	action: tensor([[-3.2417, -1.5156, -0.3990,  0.3026, -0.6738, -1.3402, -0.5993]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 93
	action: tensor([[-3.0263, -2.5682, -0.9553,  0.3050, -0.3991,  2.1383,  0.6691]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 94
	action: tensor([[-3.6650, -2.1983, -0.7563,  2.0119, -1.0601,  0.0947,  1.1997]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 95
	action: tensor([[-3.2698, -1.8430, -0.2162,  1.1545, -1.1070,  0.2524, -1.0184]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 96
	action: tensor([[-2.8141, -1.5248, -0.5427,  0.1143, -1.4274,  1.1511, -0.0163]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 97
	action: tensor([[-2.8983, -0.8980, -0.1431,  1.5053, -1.5498,  2.0458,  1.4551]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 98
	action: tensor([[-3.9829, -2.7608, -0.5817,  1.1946, -1.1045,  0.5361, -2.9091]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 99
	action: tensor([[-2.9058, -2.6655,  0.6428,  0.2226, -1.3117,  0.4212,  1.2750]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 100
	action: tensor([[-4.1529, -1.3588, -0.6062,  1.7675, -1.6741,  2.1659,  1.6146]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 101
	action: tensor([[-3.2900, -2.9361,  0.1182, -0.0265, -1.6496, -0.2483,  0.2661]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 102
	action: tensor([[-3.3282, -1.8692, -0.8366,  2.1938, -1.0814,  3.9515, -0.8280]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 103
	action: tensor([[-2.4907, -0.8455, -0.7150,  0.7812, -1.4475,  1.8893,  1.5402]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 104
	action: tensor([[-4.0521, -2.4533, -0.1539, -0.1510, -1.3444,  0.5476, -0.7422]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 105
	action: tensor([[-2.4582, -1.9321, -1.0670,  0.1595, -0.9594, -0.9576,  2.5207]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 106
	action: tensor([[-4.1604, -3.6841, -0.6511,  0.0430, -1.2435, -0.2153, -0.2363]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 107
	action: tensor([[-2.5924, -1.2234,  0.7977, -0.2307, -1.0777,  2.9373,  0.9566]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 108
	action: tensor([[-2.7860, -3.7098, -0.0852,  2.6203, -1.1750,  0.8401,  1.2783]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 109
	action: tensor([[-3.3475, -1.8037, -0.3221,  0.0724, -1.0012,  0.9761, -0.9172]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 110
	action: tensor([[-3.0803, -1.5672, -0.4580,  0.7128, -1.3584, -0.8497,  1.2626]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 111
	action: tensor([[-3.0825, -1.9905, -0.1309, -0.9156, -1.2892,  1.0012, -0.2823]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 112
	action: tensor([[-3.8087, -2.0151, -0.9438,  0.2081, -1.2639,  2.0923,  0.9125]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 113
	action: tensor([[-4.3468, -1.0795,  0.3585, -0.8013, -1.2664,  2.4660,  1.1849]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 114
	action: tensor([[-3.4298, -0.4573,  1.0445,  1.3427, -0.7421,  2.9431,  0.7972]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 115
	action: tensor([[-3.3898, -2.3974,  0.0635,  0.9803, -1.0872, -1.2090,  1.3362]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 116
	action: tensor([[-3.7436e+00,  3.6342e-03,  3.2798e-01, -1.0949e+00, -6.1680e-01,
          3.5499e-01,  1.3407e+00]], dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 117
	action: tensor([[-3.6854, -0.7868, -0.5762, -0.7264, -1.9204,  0.3071,  0.6059]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 118
	action: tensor([[-4.1053, -0.6454, -1.1343,  1.8455, -1.3860, -0.6814,  0.9788]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 119
	action: tensor([[-3.1462, -1.3133, -0.6336, -0.1619, -1.8360, -0.8175,  0.0969]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 120
	action: tensor([[-3.7041, -1.1433, -0.3849,  1.0179, -0.2030, -2.3796,  0.4062]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 121
	action: tensor([[-3.0192, -1.5554, -0.0202,  1.2291, -1.0203,  2.0824,  2.3042]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 122
	action: tensor([[-2.7904, -2.6734, -0.2131,  0.1662, -1.2878, -2.3733,  1.1707]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 123
	action: tensor([[-2.5770, -1.6561, -0.0455,  1.5582, -0.5399,  2.3118,  0.8531]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 124
	action: tensor([[-3.1449, -1.2699, -0.3339,  0.7232, -1.4984, -0.4161,  2.8635]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 125
	action: tensor([[-2.3702, -2.9792, -0.3212,  1.7872, -0.5646,  2.5539,  0.5134]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 126
	action: tensor([[-1.8470, -1.6000, -0.4910,  0.1123, -1.6417,  2.1757,  0.2265]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
epoch: 0, step: 127
	action: tensor([[-2.2852, -2.1866, -0.3438,  0.3382, -1.0734,  1.1247,  2.8967]],
       dtype=torch.float64)
	q_value: tensor([[-0.4795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.1223846079642752
LOSS epoch 0 actor 1113.9161823915547 critic 2452.276741973196
epoch: 1, step: 0
	action: tensor([[-2.7321, -0.0424,  1.7787,  2.6601, -3.1823,  1.6146,  1.8945]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 1
	action: tensor([[-3.8475, -1.7104, -0.8393, -0.7286, -1.2139, -1.7188,  1.2146]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 2
	action: tensor([[-4.6202, -1.8580, -1.3487,  1.8523, -2.9557,  1.1809,  2.1224]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 3
	action: tensor([[-5.3736, -2.6378, -0.9903, -0.3602, -0.4759, -0.9964,  0.1493]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 4
	action: tensor([[-3.7216, -1.1343,  0.6829,  1.7781, -2.0894,  2.9987,  2.3496]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 5
	action: tensor([[-3.9001, -3.1885, -1.1867, -0.0827, -2.0819,  0.9345, -0.5768]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 6
	action: tensor([[-5.2299, -2.7287, -1.6222,  1.6319, -1.4780,  1.9904,  1.2134]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 7
	action: tensor([[-3.8624, -2.0806,  0.8798,  0.0637, -0.8019,  2.2340,  0.7263]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 8
	action: tensor([[-4.3264, -1.5934,  0.8089, -0.0697, -0.7987,  3.4501, -1.1087]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 9
	action: tensor([[-4.9800, -0.4947, -1.5416,  0.8273, -1.6045, -0.8249,  2.6191]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.692790649268791, distance: 0.6342696174810976 entropy 1.623336545732092
epoch: 1, step: 10
	action: tensor([[-4.4224, -1.5203,  0.0752,  0.4680, -3.9579, -1.2120, -2.1145]],
       dtype=torch.float64)
	q_value: tensor([[-0.7027]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.852591503916534
epoch: 1, step: 11
	action: tensor([[-4.3011, -1.4621,  0.2641,  1.3601, -1.2435, -0.3824,  0.6944]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 12
	action: tensor([[-2.1697, -1.8254, -1.0659,  0.9490, -2.9472,  1.3143, -0.0318]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 13
	action: tensor([[-4.7016, -1.2168, -0.2655, -2.0684, -2.7754,  3.1867,  2.1185]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 14
	action: tensor([[-3.9286, -2.4865, -0.0421,  0.1447, -1.0212,  1.3520, -0.3012]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 15
	action: tensor([[-3.6072, -5.2107, -2.8496,  0.7870, -0.0842,  1.0511, -0.9946]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 16
	action: tensor([[-3.7144, -3.3317,  0.3374,  1.4079, -1.3197, -2.9876, -1.5832]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 17
	action: tensor([[-5.5762, -1.8192, -0.6842, -0.7753, -2.5429,  1.4247, -0.7973]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 18
	action: tensor([[-3.4098, -2.7778, -0.6042,  1.7568, -2.6620, -0.5145,  2.1775]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 19
	action: tensor([[-4.1494, -2.3849, -0.5751,  3.8571, -1.6963,  0.5801, -0.0164]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 20
	action: tensor([[-2.3380, -1.5237, -1.3509, -1.2487,  0.0198, -1.8412,  1.5837]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 21
	action: tensor([[-2.7200, -3.1557, -0.9132,  0.5475, -2.3888,  1.1961,  1.9808]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 22
	action: tensor([[-3.1889, -2.4067, -0.1615,  0.9472, -1.8142, -0.6953,  0.1435]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 23
	action: tensor([[-5.1363, -3.9625, -0.2343,  0.3870, -0.3972,  0.2266,  3.3713]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 24
	action: tensor([[-5.0603, -2.8320, -0.8176,  2.6090, -1.8115, -3.1412, -0.5823]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 25
	action: tensor([[-2.5833, -3.6871,  0.4278,  0.5882,  0.9261,  1.5869,  0.2567]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 26
	action: tensor([[-5.2527, -2.9251, -1.2023,  0.5682, -0.5110,  1.6097,  1.5211]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 27
	action: tensor([[-5.0165, -2.8419, -1.8837,  0.8127, -0.5313,  2.7945, -0.7302]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 28
	action: tensor([[-5.6123, -2.8256, -0.5774, -0.6628, -1.7179,  2.4802,  2.6551]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 29
	action: tensor([[-4.0505, -1.6335, -0.3087, -0.9620, -1.3980, -2.5074,  0.0912]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 30
	action: tensor([[-7.0255, -0.5793, -0.4221,  1.5045, -2.9362,  1.8124,  1.7350]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.5847650609819628, distance: 1.4405858252310249 entropy 1.623336545732092
epoch: 1, step: 31
	action: tensor([[-4.0877, -2.7140, -0.7105,  4.7690, -2.2820,  3.1574,  3.3036]],
       dtype=torch.float64)
	q_value: tensor([[-1.0878]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.0546423599628754
epoch: 1, step: 32
	action: tensor([[-2.3272, -1.2121,  0.8347,  1.9202, -2.7253, -4.0951,  0.6168]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 33
	action: tensor([[-4.0538, -3.9843, -0.4129, -0.4023, -2.2514, -1.8702,  0.4712]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 34
	action: tensor([[-4.0144, -2.2041, -3.0291, -1.2045, -1.5310, -0.6823, -0.4522]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 35
	action: tensor([[-3.3555, -3.3873,  0.2217,  0.0384, -1.5917,  3.5326, -0.9815]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 36
	action: tensor([[-2.3842, -0.2959, -1.1705,  0.0834, -0.8023, -1.3675, -0.7862]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 37
	action: tensor([[-3.5291, -3.8710,  1.8018, -0.5894, -2.2614,  2.3425,  0.6030]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 38
	action: tensor([[-4.2420, -0.7081,  0.0485,  1.1750, -0.7825,  0.4481,  0.3187]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 39
	action: tensor([[-3.6970, -2.1530, -0.4194, -1.1668, -1.8259,  1.9303,  1.2945]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 40
	action: tensor([[-3.7412, -1.1948,  0.6677,  2.1849, -1.4050,  3.1859,  0.3648]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 41
	action: tensor([[-5.5149, -2.5261,  0.0413,  2.7272, -3.0822,  3.7573,  0.1808]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 42
	action: tensor([[-4.7332, -3.8865, -2.1372, -0.5720, -2.2932,  0.3890,  0.2607]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 43
	action: tensor([[-5.2508, -2.5313, -0.0489,  0.0462, -2.1474,  3.1885, -0.9782]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 44
	action: tensor([[-5.4827, -3.0611,  0.8519,  0.9659, -1.3514,  1.0471,  0.1215]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 45
	action: tensor([[-2.7954, -1.6280,  0.0352, -0.1503, -1.1298,  0.9392,  1.4865]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 46
	action: tensor([[-4.1913, -4.2236, -1.2822,  1.4736, -2.2944, -0.3406,  0.4112]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 47
	action: tensor([[-3.9755, -4.8342,  1.7690, -0.3714, -2.0487,  1.0146, -1.0711]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 48
	action: tensor([[-4.7932, -4.3817,  1.1319, -1.0404, -1.2306, -1.7950,  0.3317]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 49
	action: tensor([[-6.3080, -2.8566, -1.3522,  0.6805, -2.2610, -0.2720,  2.0958]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 50
	action: tensor([[-4.0895, -0.3020, -1.3601,  0.3923, -2.1624,  0.0568,  0.5625]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 51
	action: tensor([[-6.2005, -3.5213,  0.2241,  2.4350, -1.2584,  0.6995, -1.5439]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 52
	action: tensor([[-5.2803, -2.7152,  0.4958,  1.3973, -1.2151, -0.0620, -0.3758]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 53
	action: tensor([[-4.7418, -1.8657,  0.2476,  0.2676,  0.5824,  1.7722, -0.4962]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 54
	action: tensor([[-3.4186, -1.6164,  1.4787, -1.5057, -0.1750,  3.6996,  0.4779]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 55
	action: tensor([[-3.9455, -1.4581,  1.2856,  0.0795, -1.9073,  1.9317,  0.9999]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 56
	action: tensor([[-5.0657, -3.1193,  0.7073,  1.8190, -2.0798, -0.5573, -0.3385]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 57
	action: tensor([[-3.5963, -1.8071, -0.1716, -0.6467, -2.7687, -3.0989, -1.1461]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 58
	action: tensor([[-5.3798, -2.5439, -0.7752, -2.0050, -3.0006, -1.7069,  1.4932]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 59
	action: tensor([[-5.1455, -2.1134, -0.3761, -1.0053, -1.6092,  1.1703,  0.5024]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 60
	action: tensor([[-3.7770, -0.4539, -1.7562,  3.2183, -2.0289,  1.2102, -0.5355]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 61
	action: tensor([[-4.9183, -3.6813,  0.5441,  0.4773, -1.0315,  3.4297, -1.0934]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 62
	action: tensor([[-4.9320, -2.4108, -0.2425, -1.0161, -1.3280,  2.6619,  3.6918]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 63
	action: tensor([[-3.7214, -3.2650,  0.7492,  2.5977, -1.0620, -0.9693,  1.4310]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 64
	action: tensor([[-5.3324, -3.5780,  0.1209, -0.5454, -2.1848, -0.5827,  0.7383]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 65
	action: tensor([[-4.3050, -3.1533, -2.1520, -0.9623, -2.4803,  0.4931,  0.7828]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 66
	action: tensor([[-4.2833, -3.4632, -0.7070, -0.5090, -1.9417,  1.0706,  1.1185]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 67
	action: tensor([[-3.4865, -3.7649,  0.3342,  0.0965, -1.2919,  0.5641,  0.5706]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 68
	action: tensor([[-3.7916, -1.5349, -1.5903,  0.3168, -1.6989,  1.2271,  0.7771]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 69
	action: tensor([[-4.6986, -3.2051,  0.3550, -1.4692, -0.5055,  2.0467,  0.0110]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 70
	action: tensor([[-3.9438, -2.8636, -1.9502, -0.9741, -0.8802, -3.0779, -2.0894]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 71
	action: tensor([[-4.0750, -2.3302,  0.1446,  1.4754, -1.2807,  1.7623, -1.2478]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 72
	action: tensor([[-4.5932e+00, -2.7971e-01, -3.9607e-01,  6.1825e-01, -2.3528e+00,
          1.9099e+00,  3.3656e-03]], dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 73
	action: tensor([[-4.7962, -1.1542, -0.7881, -0.7459, -1.8050, -0.5057,  3.9846]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.9212610327744661, distance: 1.586170543790174 entropy 1.623336545732092
epoch: 1, step: 74
	action: tensor([[-6.4797, -3.3434,  0.7074,  0.8088,  0.3711, -1.0561, -2.0860]],
       dtype=torch.float64)
	q_value: tensor([[-0.6350]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.8573879931170676
epoch: 1, step: 75
	action: tensor([[-3.1455, -2.1080, -1.2919,  1.2701, -2.3346, -1.3721,  0.8283]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 76
	action: tensor([[-5.2988, -3.9946,  0.3272,  3.1250, -1.4398, -1.4602,  1.7359]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 77
	action: tensor([[-5.5271,  0.1739, -1.7884,  1.2556, -0.9277,  1.3967,  3.2805]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.3188099912985932, distance: 0.9444757855094502 entropy 1.623336545732092
epoch: 1, step: 78
	action: tensor([[-7.3483, -3.9417,  0.5564,  1.6363, -2.6528,  5.2581,  2.0107]],
       dtype=torch.float64)
	q_value: tensor([[-0.6785]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.959279074095797
epoch: 1, step: 79
	action: tensor([[-3.7186, -2.7153, -0.2409, -0.1573, -1.9154,  0.6587, -2.4662]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 80
	action: tensor([[-3.9036, -4.2543, -1.4373,  0.7552, -0.9529, -1.3020,  3.1358]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 81
	action: tensor([[-3.2418, -3.2300,  0.1969,  2.0721, -2.3389, -1.6953, -0.4503]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 82
	action: tensor([[-4.6987, -4.0206, -0.7119, -0.4675, -2.6795,  1.3594,  0.5319]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 83
	action: tensor([[-4.8846, -0.5768,  0.2361, -0.7287, -1.4852, -3.4218,  2.2656]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 84
	action: tensor([[-4.1252, -1.0401,  0.5854, -0.4373, -1.0508,  1.2526,  2.2737]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 85
	action: tensor([[-3.6739, -1.7952, -1.3177, -0.7736, -1.6245,  1.0250,  1.8963]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 86
	action: tensor([[-2.6761, -2.3376,  1.5054,  2.8144, -2.0374,  3.7107,  1.7428]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 87
	action: tensor([[-2.8440, -2.2011, -1.2875,  1.7830, -2.3775,  0.2755,  0.3961]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 88
	action: tensor([[-4.8188, -2.8654,  1.7320, -1.7347, -2.0014,  2.1870,  1.8069]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 89
	action: tensor([[-6.0172, -2.0672,  0.2985, -1.3140, -1.1619, -0.1593,  1.4505]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 90
	action: tensor([[-3.1164, -1.9633, -1.1235,  1.6484, -1.0955, -1.5296, -1.2697]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 91
	action: tensor([[-4.1065, -2.8707, -0.1597,  1.0957, -1.7701,  1.4326, -3.4560]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 92
	action: tensor([[-3.2109, -1.5261, -0.6747,  1.6958, -1.6994,  1.8788,  0.9957]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 93
	action: tensor([[-5.5486, -3.8942, -0.3282, -1.2957, -1.9264, -1.2236,  1.9077]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 94
	action: tensor([[-3.2015, -2.3378, -2.0118,  1.7418, -0.3328,  2.6298,  1.7422]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 95
	action: tensor([[-4.0120, -1.6597,  0.7883,  2.0072, -0.4189,  4.1594, -2.1012]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 96
	action: tensor([[-4.6608, -2.2052, -0.9369,  0.9519, -1.2656, -0.7918,  2.0239]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 97
	action: tensor([[-4.9020, -2.9428, -1.5963,  1.8935, -2.1132,  0.2682,  0.9784]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 98
	action: tensor([[-4.2221, -2.5984, -1.2878,  1.0772, -0.8342,  2.1526, -0.0501]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 99
	action: tensor([[-2.6250, -2.0760, -0.4321,  0.1808, -1.6785, -2.3176,  3.3927]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 100
	action: tensor([[-5.8605, -1.1005,  0.8962, -0.4022, -1.6519, -2.7941, -1.1714]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 101
	action: tensor([[-3.0926, -0.8144,  1.1916,  1.8925, -1.1970,  0.2319, -1.0403]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 102
	action: tensor([[-4.5475, -1.1908, -0.5508,  0.9402, -0.4961, -0.4484, -0.1980]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 103
	action: tensor([[-3.0044, -4.1820,  0.7801, -0.5797, -1.8671,  0.5844, -3.8502]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 104
	action: tensor([[-6.4990, -2.1705, -0.3530,  1.9955, -1.6817,  1.5310,  1.7003]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 105
	action: tensor([[-4.5849, -2.8642, -0.4057,  1.7397, -1.3416,  2.9778, -1.0682]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 106
	action: tensor([[-4.1154, -2.7854, -0.1730,  0.4390, -0.3347,  1.3940,  1.8655]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 107
	action: tensor([[-4.0559, -5.2508,  0.1453,  0.8665, -1.4924,  0.2961, -0.4829]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 108
	action: tensor([[-3.1735, -3.9347, -0.9138, -0.6355, -1.3466,  0.9271,  2.0527]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 109
	action: tensor([[-2.5440, -0.9651,  0.3043,  0.8838, -1.2554,  0.9485, -1.5618]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 110
	action: tensor([[-4.6708, -2.2301, -0.4218,  1.3545, -2.8294, -2.0573,  0.8536]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 111
	action: tensor([[-4.8577, -2.3176, -0.3239,  1.1295, -2.1447,  0.4281,  2.6014]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 112
	action: tensor([[-4.7172, -0.7596,  1.2271, -1.2909, -0.8601, -1.3896,  1.9858]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 113
	action: tensor([[-3.4416, -2.7526, -0.2679,  1.2375, -1.5236,  1.7026,  1.5135]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 114
	action: tensor([[-4.2163, -2.0295, -0.9724,  3.6067, -1.6960,  1.7352,  2.0499]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 115
	action: tensor([[-4.5982, -0.8664,  0.0997,  4.7172, -1.6588, -1.1303,  1.2818]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 116
	action: tensor([[-5.3106e+00, -1.2393e+00,  2.3739e-03,  8.5598e-01, -1.8455e+00,
         -2.0183e+00, -1.0596e-01]], dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.2915096034688154, distance: 0.963215975912153 entropy 1.623336545732092
epoch: 1, step: 117
	action: tensor([[-4.9863, -5.3402, -1.6587,  0.4954, -2.5385,  2.4611, -0.9337]],
       dtype=torch.float64)
	q_value: tensor([[-0.6649]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.7828667514586904
epoch: 1, step: 118
	action: tensor([[-4.4730, -3.2077, -0.5601,  2.2030, -0.5844,  2.3352, -1.3984]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 119
	action: tensor([[-5.1052, -2.4636, -1.3186,  1.3005,  0.0994, -1.1659, -0.7156]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 120
	action: tensor([[-5.2954, -3.4759, -1.6704,  4.0040, -0.2147, -0.1543,  1.5856]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 121
	action: tensor([[-5.8934, -1.5608, -0.0411,  1.7121, -0.9869, -0.0379,  0.5771]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 122
	action: tensor([[-4.9063, -2.2791,  0.5437, -0.7164, -0.2662,  1.5417, -1.1825]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 123
	action: tensor([[-3.2767, -2.4911, -0.8957,  0.5156, -2.2190,  1.4340,  0.9959]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 124
	action: tensor([[-4.1226, -2.8509, -1.1636, -0.5471, -1.0307, -0.8850, -0.2903]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 125
	action: tensor([[-4.6067e+00, -4.5335e+00, -1.6207e+00,  4.9623e-01, -1.4048e+00,
          2.6452e+00, -2.7376e-04]], dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 126
	action: tensor([[-3.2441, -1.1780, -0.8726,  4.8919, -2.9732,  2.4513,  0.2058]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
epoch: 1, step: 127
	action: tensor([[-3.8102, -3.0693,  0.3982,  0.6568, -1.6552, -0.9525, -0.3015]],
       dtype=torch.float64)
	q_value: tensor([[-0.8563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.623336545732092
LOSS epoch 1 actor 997.2206901882932 critic 2404.7197761531665
epoch: 2, step: 0
	action: tensor([[-5.5639, -4.8353,  0.5924,  1.1330, -0.2295, -3.8215,  4.8914]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 1
	action: tensor([[-3.4913, -4.1375, -1.1178,  1.6039, -1.3844,  0.2955, -1.6537]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 2
	action: tensor([[-6.4232, -1.6625,  0.1043,  2.3720, -3.3292,  6.3016, -0.1004]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 3
	action: tensor([[-5.5930, -1.6966,  1.0129,  2.2240, -1.7474,  0.7669, -0.1697]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 4
	action: tensor([[-5.7507, -0.9820, -0.0717, -1.4308, -4.6064,  0.4715,  0.6738]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.6663577893141042, distance: 1.4772051777604622 entropy 2.02934624147291
epoch: 2, step: 5
	action: tensor([[-3.7504, -3.4568, -0.2192,  2.6261, -1.9201,  2.1588, -0.5370]],
       dtype=torch.float64)
	q_value: tensor([[-0.5997]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.7062459272451045
epoch: 2, step: 6
	action: tensor([[-3.4080, -6.7188, -0.4846, -1.5033, -0.8907, -0.0418, -0.9684]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 7
	action: tensor([[-5.0007, -1.5792,  0.1355, -0.9482, -3.5393, -0.7502,  5.7733]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 8
	action: tensor([[-6.3929, -3.5477, -0.9721,  3.8129, -4.2116,  1.0459, -0.7874]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 9
	action: tensor([[-5.8300, -4.1832,  2.9312, -0.2472, -0.7274,  4.3844,  0.1722]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 10
	action: tensor([[-5.1451, -1.1479, -0.8212,  0.3961, -2.5191, -1.9468,  3.7425]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.4981395423431756, distance: 0.8106776174036087 entropy 2.02934624147291
epoch: 2, step: 11
	action: tensor([[-8.8291, -1.9999,  1.0084, -1.1091, -3.9578,  2.5872,  1.6846]],
       dtype=torch.float64)
	q_value: tensor([[-1.4621]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.4715979648419846
epoch: 2, step: 12
	action: tensor([[-6.6621, -6.2185, -0.0068,  5.1583, -4.0018, -1.5706,  0.2313]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.40282716176388234, distance: 1.355372832789592 entropy 2.02934624147291
epoch: 2, step: 13
	action: tensor([[-3.7176, -3.1416,  1.1653, -1.8250, -3.6737,  0.4535,  3.5891]],
       dtype=torch.float64)
	q_value: tensor([[-0.9742]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.9269894440873732
epoch: 2, step: 14
	action: tensor([[-6.3003, -1.4017, -0.4560,  2.5156, -3.8367,  4.0610,  0.4082]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 15
	action: tensor([[-4.2192, -2.2231,  1.3956,  2.4981,  0.0461,  0.5860,  0.7535]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 16
	action: tensor([[-5.0738, -4.1672, -1.1892,  2.3962, -1.3620,  3.8825, -0.6338]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 17
	action: tensor([[-5.7549, -5.3746, -0.4117,  3.7385, -4.2489,  0.3613, -2.3721]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 18
	action: tensor([[-5.3427, -4.6493, -0.8275, -2.7632,  0.8506,  0.2361, -2.4250]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 19
	action: tensor([[-3.4194, -4.9083,  0.2477,  1.7502, -2.7855, -0.5493, -2.9075]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 20
	action: tensor([[-4.6870, -5.2937,  0.8994, -5.2125, -0.1542,  1.0061,  4.7172]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 21
	action: tensor([[-5.3540, -2.9344, -0.9706,  2.6947, -2.2542,  1.9341,  2.5005]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 22
	action: tensor([[-5.4634e+00, -1.4777e+00, -3.3416e+00,  2.6193e+00, -2.0113e+00,
          1.6077e-01,  5.1009e-03]], dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 23
	action: tensor([[-2.9285, -3.4577,  1.8092,  3.5192, -3.8675, -0.7529,  0.3818]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 24
	action: tensor([[-7.6425, -2.2042,  3.3178,  1.7871, -1.0299,  0.4791,  4.4231]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 25
	action: tensor([[-6.0628, -1.2988,  0.5858,  0.4188,  1.0158,  3.2745, -2.8861]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 26
	action: tensor([[-6.1221, -4.0618, -1.6784,  2.0038, -1.4539, -0.8974, -2.3789]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 27
	action: tensor([[-5.2091, -1.7865, -0.6597,  0.1020, -3.1401,  1.0679,  1.0219]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 28
	action: tensor([[-5.7290e+00, -6.4744e+00, -2.1524e+00, -1.5634e-03, -8.4176e-01,
         -1.9745e+00,  3.5201e+00]], dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.878351094571604, distance: 0.3991267135324901 entropy 2.02934624147291
epoch: 2, step: 29
	action: tensor([[-5.2455, -6.9789, -1.0794, -2.6658, -5.7065, -0.2925,  2.6240]],
       dtype=torch.float64)
	q_value: tensor([[-1.4489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.4060794603440976
epoch: 2, step: 30
	action: tensor([[-6.3561, -4.8827,  0.2559,  2.9697,  0.2983,  4.0360,  2.7533]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 31
	action: tensor([[-5.6212, -5.1927,  0.4422,  2.2276, -2.0311,  1.1714,  2.5687]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.1274733941778774, distance: 1.068922041933995 entropy 2.02934624147291
epoch: 2, step: 32
	action: tensor([[-7.5806, -4.9905, -1.1075, -0.1656, -2.0860,  4.6755,  4.2383]],
       dtype=torch.float64)
	q_value: tensor([[-1.3414]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.2501488069168643
epoch: 2, step: 33
	action: tensor([[-5.2057, -3.9011,  1.1480,  5.6837,  0.4213,  4.7206,  0.9201]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 34
	action: tensor([[-6.2618, -5.3247,  2.8080,  1.9188, -1.3019, -2.3554, -0.0599]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 35
	action: tensor([[-5.1888, -2.1359, -2.8010,  1.1078, -1.0421, -0.2020,  1.7406]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 36
	action: tensor([[-7.0056, -1.5302, -0.4621,  0.6298, -3.9752, -2.6902, -1.9579]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 37
	action: tensor([[-7.0382, -4.0056,  1.3435, -2.2849, -2.2702, -2.6195,  2.1942]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 38
	action: tensor([[-4.8583, -3.6757,  0.1735,  0.6605,  0.4313,  3.7501,  4.9978]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 39
	action: tensor([[-4.9686, -3.1398, -0.6566,  1.2414,  1.0303,  1.0963,  1.3162]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 40
	action: tensor([[-2.6215, -3.3651, -0.3400, -1.5891, -2.3947,  3.8118,  0.4303]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 41
	action: tensor([[-3.0127, -2.7298, -0.5591,  1.8055, -2.0049, -6.3383, -0.0149]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 42
	action: tensor([[-4.3767, -2.5283,  2.1690,  1.8043, -1.8718,  2.0290,  3.8811]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 43
	action: tensor([[-6.5055, -1.7084, -0.8704, -1.6719, -1.9081,  3.2326, -0.4233]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 44
	action: tensor([[-7.4941, -1.3952, -2.5448,  2.2958, -0.7083,  0.1762,  3.0087]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 45
	action: tensor([[-6.4821, -3.5276, -3.8450,  2.5355, -4.0955,  2.6374,  0.9365]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 46
	action: tensor([[-7.7560, -3.1956, -2.0965,  4.9432, -0.7039, -5.2518,  1.3223]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 47
	action: tensor([[-7.9268, -1.2864, -0.9703,  3.9617, -4.3547, -0.8338, -0.8752]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 48
	action: tensor([[-3.7068, -2.2013, -2.6830,  1.0233,  0.0351,  0.2252, -1.1215]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 49
	action: tensor([[-4.7151, -1.9749,  0.6725,  1.1171, -1.0895,  2.9553,  3.2609]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 50
	action: tensor([[-4.9775,  0.6018,  2.0492,  0.7705, -3.7563, -1.7775,  0.4335]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 51
	action: tensor([[-4.9203, -3.1971,  0.0993,  1.8231, -2.5382,  1.8102,  2.6781]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 52
	action: tensor([[-7.2980, -2.2658, -3.7091,  0.6978, -2.6216, -1.0990,  2.0482]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 53
	action: tensor([[-7.0558, -0.8863, -0.1139,  2.8989, -2.7002,  0.1554,  1.0916]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 54
	action: tensor([[-7.9165, -2.1361,  1.8163, -0.7849, -4.1173,  4.2222, -4.3347]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 55
	action: tensor([[-4.9144, -3.3647, -0.8594,  2.2968, -1.9514,  2.4957,  3.0121]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 56
	action: tensor([[-7.3440, -3.7573,  1.0462,  1.8066, -2.0023, -0.7824,  2.9337]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 57
	action: tensor([[-3.8618, -2.0875, -1.3565,  3.1073, -1.7992,  2.8876, -0.3702]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 58
	action: tensor([[-5.7486, -2.9223, -1.0151,  5.3652, -3.5280, -0.2723,  3.6798]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 59
	action: tensor([[-2.4076, -4.9383, -1.5466,  5.5841, -0.6777,  3.0994, -1.5305]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 60
	action: tensor([[-5.0025, -3.0764, -0.3284, -2.2052, -0.3199, -2.4310,  1.1374]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 61
	action: tensor([[-5.0385, -3.6575,  0.8100,  0.4348,  0.8089,  4.0999,  3.7516]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 62
	action: tensor([[-5.0277, -4.7167,  1.0493,  2.8683, -2.5237,  0.5262, -1.7292]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 63
	action: tensor([[-5.6685, -2.9718,  0.3615,  1.1683, -4.9325, -0.3104, -0.0559]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 64
	action: tensor([[-4.5545, -1.9373, -0.5141,  1.9675, -0.3201,  0.1731,  3.8725]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 65
	action: tensor([[-8.8471, -3.7896, -0.4965, -2.3411, -0.7096,  1.1786,  1.2500]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 66
	action: tensor([[-8.4990, -3.2045,  0.8006,  1.4558, -1.3292, -5.4225,  2.5551]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 67
	action: tensor([[-10.7856,  -4.3578,   0.9450,  -0.9615,  -2.9935,   2.4170,   0.9422]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 68
	action: tensor([[-6.5447, -1.3176,  1.5586, -1.2637, -2.0758, -3.2177,  3.7204]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 69
	action: tensor([[-4.7587, -4.1358, -0.2368,  2.2025, -0.9812,  0.5299,  1.5224]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 70
	action: tensor([[-4.0732, -2.0645, -3.0315,  1.9633, -0.7159,  1.4727,  2.0304]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 71
	action: tensor([[-5.8411, -3.5679, -0.0243,  2.0135, -2.6432,  2.4286,  3.6699]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 72
	action: tensor([[-5.4428, -3.2917,  0.3692, -3.4540, -2.5505,  2.8648, -2.6412]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 73
	action: tensor([[-5.1991, -7.1032, -1.3021, -3.2769, -3.0407, -1.8139,  2.4900]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 74
	action: tensor([[-5.1239, -0.8203, -1.3653,  4.3791, -0.3642,  0.1255,  0.2589]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 75
	action: tensor([[-8.0223, -3.9509, -0.3620,  5.0459, -0.9573,  6.3817, -0.5816]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 76
	action: tensor([[-6.5684, -0.7609,  1.7269, -0.1105, -1.5440, -0.0954,  0.8685]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.7548894866443512, distance: 1.5159384880007285 entropy 2.02934624147291
epoch: 2, step: 77
	action: tensor([[-5.3672, -2.5131, -2.0906,  0.7478, -1.2476, -0.5427,  2.7830]],
       dtype=torch.float64)
	q_value: tensor([[-1.0136]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 1.9333832486719689
epoch: 2, step: 78
	action: tensor([[-5.6907, -2.6641, -4.9434,  3.3072, -2.3730,  2.1810,  2.6249]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 79
	action: tensor([[-7.0836, -2.7832, -2.1741,  2.0285, -2.7123, -5.1074, -0.5791]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 80
	action: tensor([[-5.6309, -3.6943,  0.0058, -0.4622, -1.1511, -1.7381,  3.0608]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 81
	action: tensor([[-6.7259, -0.6063, -0.6620, -1.6082, -3.7636, -4.3669,  1.2313]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 82
	action: tensor([[-7.3769, -6.3092,  0.6149,  1.6746, -3.1714,  1.8182,  4.7287]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.21805979062021974, distance: 1.2629640735681322 entropy 2.02934624147291
epoch: 2, step: 83
	action: tensor([[-7.6066, -6.1199, -1.0329,  4.1690, -2.5830, -1.7564, -2.8666]],
       dtype=torch.float64)
	q_value: tensor([[-0.9475]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.175404700693266
epoch: 2, step: 84
	action: tensor([[-5.9483, -8.0401,  1.8205,  0.2995, -1.6411, -1.6433,  1.7884]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 85
	action: tensor([[-9.4646, -1.2078,  0.4056, -1.7359, -2.2673, -0.3035,  0.6125]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 86
	action: tensor([[-2.7617, -5.9345, -0.2597,  0.4231, -3.2044,  0.4417,  3.3529]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 87
	action: tensor([[-7.9142, -5.0745,  0.3665, -0.4195, -1.0837,  1.9458,  3.3544]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 88
	action: tensor([[-4.9140, -3.5029, -0.2423,  0.9898, -2.3413,  4.2197,  0.3669]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 89
	action: tensor([[-7.1981, -2.1423, -1.0110,  1.8554, -2.3782, -2.6951,  1.5836]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 90
	action: tensor([[-6.1999, -5.7426, -1.7590, -2.4837, -2.8094, -0.6206,  3.9473]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 91
	action: tensor([[-2.0914,  1.5908,  0.8867,  0.0469, -0.6889,  1.1337,  4.3525]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 92
	action: tensor([[-7.4091, -3.2251, -1.6326, -3.9015, -1.7944, -0.2352,  2.9132]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 93
	action: tensor([[-3.4507, -4.1044, -0.7612,  1.9392, -3.6963,  0.5165,  0.3990]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 94
	action: tensor([[-7.1307, -2.0101,  0.5480,  3.3743, -0.5707, -1.4568,  0.6979]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 95
	action: tensor([[-5.7232, -2.0710, -1.3901, -0.8664, -1.4063,  1.7672,  0.1823]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 96
	action: tensor([[-6.0144, -1.2449,  2.0429, -0.5193, -3.6754,  4.1213, -1.2143]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 97
	action: tensor([[-4.0861, -8.1770, -1.4688,  0.8269, -3.0050,  1.4778,  1.1918]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 98
	action: tensor([[-5.8556, -3.7506, -1.0155,  2.8125, -0.7584,  1.1353,  0.1368]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 99
	action: tensor([[-3.9935e+00, -1.7067e+00,  2.2208e-01,  3.9125e-03, -6.9838e-01,
          3.7712e+00, -1.1521e+00]], dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 100
	action: tensor([[-2.9015, -5.1110, -1.4731,  0.0929, -2.9292,  2.8256,  3.1899]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 101
	action: tensor([[-5.8469, -1.5026,  0.2555, -1.3937, -2.8550,  1.4905,  2.5574]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 102
	action: tensor([[-3.3925, -5.9787, -3.4004,  5.0730, -0.8740,  3.0213,  0.4995]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 103
	action: tensor([[-6.2671, -1.6695, -0.1703,  4.1829, -1.7091,  1.2804,  1.9411]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 104
	action: tensor([[-4.3114, -2.8287,  0.1866, -0.2140, -1.5915,  0.4818,  2.0205]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 105
	action: tensor([[-6.4620, -2.4875, -0.1076, -2.6308, -1.9569,  0.9909, -0.4960]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 106
	action: tensor([[-4.3932, -2.8455, -2.8102,  0.3407, -2.9789,  1.0494, -1.1249]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 107
	action: tensor([[-5.2293, -5.0716,  0.1526, -0.2909, -2.3866,  5.5235,  3.6863]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 108
	action: tensor([[-8.2103, -3.8180,  0.7895,  3.3821, -1.9727, -5.4506, -2.7377]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 109
	action: tensor([[-2.7689, -4.0911, -1.5949,  0.3132, -1.6002,  2.6734,  0.1432]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 110
	action: tensor([[-3.4134, -2.3332, -0.3600, -0.0853, -1.6943, -0.5786, -5.3589]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 111
	action: tensor([[-6.2378, -3.9716, -0.6529,  0.9712, -0.1358, -0.6726,  3.3533]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 112
	action: tensor([[-6.5226, -4.2310, -2.0062, -0.8905, -2.1972,  1.1161,  1.0552]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 113
	action: tensor([[-6.3718, -3.3355, -1.0193,  2.4586, -0.1727,  2.1767,  0.4775]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 114
	action: tensor([[-5.0804, -0.9552, -0.5612,  2.1999,  1.2544, -1.7728,  1.3700]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.4803201636960127, distance: 0.824944300722123 entropy 2.02934624147291
epoch: 2, step: 115
	action: tensor([[-5.5638, -3.5635, -3.7195, -0.5686, -2.0039,  1.8245,  0.5957]],
       dtype=torch.float64)
	q_value: tensor([[-1.1847]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.111636164990148
epoch: 2, step: 116
	action: tensor([[-7.9987, -1.2291, -1.4069,  1.7742, -0.7504, -0.6007,  1.1436]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 117
	action: tensor([[-4.8832, -3.1366, -1.5945,  2.0289, -3.2614, -2.6183,  4.0651]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 118
	action: tensor([[-5.9125, -3.3460, -0.8490,  0.1294, -0.5423,  1.1281,  3.7814]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 119
	action: tensor([[-3.6757, -2.5926, -2.1614,  1.3134, -4.5182,  2.0409,  5.2700]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 120
	action: tensor([[-7.2146, -2.3739, -1.7020,  1.8407, -3.5621,  5.7763,  5.8229]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 121
	action: tensor([[-7.9702, -2.6376,  0.6237, -3.6346, -2.2031,  0.8837,  4.2100]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 122
	action: tensor([[-3.8575,  0.2133, -0.2149,  1.6581, -0.1393,  4.4519, -0.5707]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 123
	action: tensor([[-4.3248, -5.9607,  0.7089,  0.8473, -0.4969,  1.7650,  4.4012]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 124
	action: tensor([[-1.8814, -3.8140,  2.2046,  0.7180, -3.1165,  0.5047,  3.3157]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 125
	action: tensor([[-5.7106, -4.7844,  0.5525,  7.0980, -3.8183, -0.5899,  0.1573]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 126
	action: tensor([[-7.9405,  0.2430,  0.1261, -0.2494, -1.2735,  2.3675,  1.4590]],
       dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
epoch: 2, step: 127
	action: tensor([[-4.9928e+00, -3.3145e+00,  9.2004e-02, -3.7660e-01, -9.3766e-01,
          3.6972e-03,  5.3884e-01]], dtype=torch.float64)
	q_value: tensor([[-1.4117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.02934624147291
LOSS epoch 2 actor 904.1119340887369 critic 2345.4540658558753
epoch: 3, step: 0
	action: tensor([[-7.2448, -5.4605, -5.3909, -4.6118, -4.0225,  1.3798, -2.4425]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 1
	action: tensor([[-7.7968, -3.3027, -1.7801, -2.1738, -2.2468,  2.3206,  2.3204]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 2
	action: tensor([[-7.6805, -1.0838, -0.3326,  0.6727, -3.4146,  6.0298,  1.7089]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -1.6942057744798142, distance: 1.8783307768954183 entropy 2.382312461581956
epoch: 3, step: 3
	action: tensor([[-11.8353,  -4.9343,   1.7357,   1.0637,  -0.3839,  -5.4882,   0.5526]],
       dtype=torch.float64)
	q_value: tensor([[-1.8040]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.563994396861927
epoch: 3, step: 4
	action: tensor([[-1.8245, -2.8860, -4.4547,  3.7871, -6.3447, -5.3542, -1.0902]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 5
	action: tensor([[-4.2552, -4.9011,  1.4703,  1.4177,  0.8852,  0.7282,  0.0479]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 6
	action: tensor([[-3.2547, -2.6308, -2.0055,  3.3549, -1.6652,  0.0666,  8.4950]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 7
	action: tensor([[-5.8553, -3.3736, -1.3258,  3.5547, -2.8251, 13.1073,  6.9675]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 8
	action: tensor([[-6.2841, -0.0387,  3.6947,  1.7944,  1.9356,  1.5912,  2.5107]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.15985735266272783, distance: 1.2324206972660532 entropy 2.382312461581956
epoch: 3, step: 9
	action: tensor([[-7.2526, -8.4262,  2.5146,  2.3448, -1.8764, -1.2120,  1.4788]],
       dtype=torch.float64)
	q_value: tensor([[-2.4346]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.6725072959594662
epoch: 3, step: 10
	action: tensor([[-7.2275, -0.9170, -0.3898,  1.1592, -5.0696,  3.2910,  4.3154]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 11
	action: tensor([[-8.9164, -0.6681,  0.9772,  1.6515, -0.8131, -0.9055,  1.3840]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 12
	action: tensor([[-7.0498, -3.8291,  0.8892, -0.1507, -3.6771,  8.0139,  1.2648]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 13
	action: tensor([[-8.1815, -3.1753,  0.3056,  3.2825,  1.0330, -3.8991,  2.7067]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 14
	action: tensor([[-7.0967, -7.6346,  0.4208, -1.3800, -3.8871, -5.0526,  3.8598]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 15
	action: tensor([[-5.5754, -2.7803,  0.0649,  8.0253, -2.0835, -2.5687,  5.4063]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 16
	action: tensor([[-6.0163, -4.6151,  1.8466, -2.6442, -4.7721, -6.0918,  3.6090]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 17
	action: tensor([[-9.9242, -3.4589,  1.2509, -0.9011, -4.7663,  0.8612,  2.4282]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 18
	action: tensor([[-5.6147, -4.9021,  1.8220,  1.6862, -1.9316, -4.5240,  2.8818]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 19
	action: tensor([[-6.6663, -6.7348,  1.0660, -1.6051, -5.4298, -2.9465, -2.1537]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 20
	action: tensor([[-3.9072, -0.4411,  1.2458,  2.5623, -2.1603, -0.9880, -1.6228]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 21
	action: tensor([[-11.1699,  -7.3269,  -2.9435,   1.5312,  -1.8364,  -4.1089,   1.7002]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 22
	action: tensor([[-6.0516, -2.6772, -0.9189, -3.7696, -6.7472,  1.4598, -1.6738]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 23
	action: tensor([[-5.7713, -3.5956, -3.7401, -1.3620, -3.7602,  0.7897,  5.0360]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 24
	action: tensor([[-6.7343, -0.2489,  3.0260,  0.5337, -4.2788, -3.6759,  6.3001]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 25
	action: tensor([[-5.9237,  0.6331,  1.2529, -5.3545, -1.0377,  2.2257, -0.7407]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 26
	action: tensor([[-6.0929, -3.9175,  3.4214, -1.2517, -2.3716,  3.9189, -3.5173]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 27
	action: tensor([[-6.3420, -0.2031, -1.1649, -3.0225, -4.5814,  0.4254,  0.9488]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 28
	action: tensor([[-7.9133, -5.6024, -0.3483,  1.4957, -5.2680,  2.4098, -2.4392]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 29
	action: tensor([[-3.7700, -0.0572,  0.4997,  2.4389, -4.4194, -4.9740,  4.3270]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 30
	action: tensor([[-1.7346, -2.5649,  0.2554,  5.6650, -4.8144,  8.0448, -0.4980]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 31
	action: tensor([[-8.7450, -6.9883, -1.5745,  0.2170, -0.9803, -0.3785,  5.2400]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 32
	action: tensor([[-11.1425,   1.6321,  -1.9576,  -2.1887,  -0.5792,   1.5299,   5.0947]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 33
	action: tensor([[-7.2722, -5.6868, -2.5012,  0.5597, -0.7491,  0.4296,  2.6673]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -1.000079666797423, distance: 1.6183793958434685 entropy 2.382312461581956
epoch: 3, step: 34
	action: tensor([[-8.4808, -5.0496,  3.8239, -3.1796, -3.1525,  7.0582,  7.3257]],
       dtype=torch.float64)
	q_value: tensor([[-2.4729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.7077553352113592
epoch: 3, step: 35
	action: tensor([[-12.1782,  -5.8535,  -2.0865,   0.7588,  -3.0867,   0.3489,  -1.0301]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.39696382644626693, distance: 0.8886451510255358 entropy 2.382312461581956
epoch: 3, step: 36
	action: tensor([[ -6.9783, -10.5369,   5.1115,   5.3495,  -0.4939,   6.7676,   8.6698]],
       dtype=torch.float64)
	q_value: tensor([[-2.6534]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.8107516990722923
epoch: 3, step: 37
	action: tensor([[-9.5919, -4.6973, -0.3240,  0.3176, -2.2871,  9.4669,  3.0586]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 38
	action: tensor([[-8.2973, -2.2073,  1.4962,  3.2543, -0.3683, -0.9583,  4.0196]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 39
	action: tensor([[-6.7467, -5.5565, -2.3494,  1.9174, -8.0782, -3.8239,  2.5613]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 40
	action: tensor([[-7.2818, -3.3487, -4.6641,  1.2951, -5.3299,  3.4402,  2.5518]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 41
	action: tensor([[-6.5330, -5.2107,  1.8513,  2.0376, -6.6015, -0.9748,  0.6868]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.8709231422878945, distance: 0.4111316255720801 entropy 2.382312461581956
epoch: 3, step: 42
	action: tensor([[-7.4789, -0.5366, -4.5805,  2.5435, -2.3035,  2.4948,  0.4295]],
       dtype=torch.float64)
	q_value: tensor([[-1.6380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.3241174901939767
epoch: 3, step: 43
	action: tensor([[-4.7986, -4.8281,  1.2079,  3.0276, -3.0160, -1.6316,  3.3119]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 44
	action: tensor([[-8.5482, -3.1043, -4.0660,  1.7452, -1.2899,  4.0402,  1.4587]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 45
	action: tensor([[-11.1903,  -2.3780,  -1.2206,  -0.7588,  -4.0436,  -3.6007,  -1.7281]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 46
	action: tensor([[-6.6585, -8.3462, -1.7519,  2.3148, -5.4945,  0.9390, -0.3606]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 47
	action: tensor([[-11.6279,  -4.0377,  -2.9223,  -2.3539,  -3.7847,   2.2369,  -2.0208]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 48
	action: tensor([[-12.7393,   0.2193,  -4.3037,   2.7831,   0.9244,   6.0279,   1.6270]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 49
	action: tensor([[-3.0400, -6.0578,  0.3934, -4.3205, -3.3025,  2.2129,  2.7555]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 50
	action: tensor([[-3.8256,  1.6358,  1.7551,  3.0363, -2.2493, -2.8939,  2.8148]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 51
	action: tensor([[-7.2375, -7.6691, -0.4881, -2.2777, -1.0430,  0.6403,  3.0306]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 52
	action: tensor([[-7.2899, -5.8382, -0.5947,  0.1269,  1.0204, -3.2446,  2.7781]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 53
	action: tensor([[-4.7998, -0.3332, -1.5205,  1.1989, -7.4178, -1.3582, -1.7140]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.8378033792764055, distance: 0.4608691034566375 entropy 2.382312461581956
epoch: 3, step: 54
	action: tensor([[-7.5212, -7.4873,  1.4169,  1.6430,  4.1246, 11.2960, -0.7781]],
       dtype=torch.float64)
	q_value: tensor([[-1.8758]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.4180862225593117, distance: 0.8729432539499271 entropy 2.5809962336741594
epoch: 3, step: 55
	action: tensor([[-8.1957, -9.1644, -0.3115,  0.4389, -5.6092,  2.8019, -4.1355]],
       dtype=torch.float64)
	q_value: tensor([[-2.1976]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.738825651985287
epoch: 3, step: 56
	action: tensor([[-7.5400e+00, -2.6582e+00,  3.4979e+00,  3.1805e+00, -3.6023e-01,
          2.0705e-03,  4.8963e-02]], dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 57
	action: tensor([[-5.9421, -5.9064, -2.1146,  5.4680,  2.5039,  5.2587,  3.2363]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 58
	action: tensor([[-8.1360, -4.7105,  1.9713, -0.4556, -4.3286, -1.6423,  3.3479]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 59
	action: tensor([[-6.2589, -3.4782, -5.2391,  1.8825, -1.7220, -2.8028,  0.7479]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 60
	action: tensor([[-5.1460, -6.6260, -0.7076, -6.9245, -2.1416,  1.8934,  5.2130]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.1303705220675868, distance: 1.0671459477930934 entropy 2.382312461581956
epoch: 3, step: 61
	action: tensor([[-8.1144, -2.3485,  1.3372, -2.2691, -2.2780,  3.5980,  4.0414]],
       dtype=torch.float64)
	q_value: tensor([[-1.9389]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.517262121270231
epoch: 3, step: 62
	action: tensor([[-5.5800,  0.9895, -3.5459, -2.2129,  0.1848,  0.6797, -2.3985]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.07787188434696468, distance: 1.0988852023602322 entropy 2.382312461581956
epoch: 3, step: 63
	action: tensor([[-8.2352, -3.9967,  1.0199, -1.5054, -2.7438,  2.8158, -1.2454]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 64
	action: tensor([[-7.4977, -5.4864,  0.1913,  0.4143,  0.4209,  2.6269, -1.6732]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 65
	action: tensor([[-5.8702, -7.0580, -2.5593, -5.1786, -3.8588, -0.9560,  0.9594]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 66
	action: tensor([[-3.7523, -6.4860, -3.4242,  3.8746, -0.8903,  2.3308,  1.4940]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 67
	action: tensor([[-9.4133, -5.6923,  1.3112,  5.0715, -0.6758, -4.3484,  3.8505]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 68
	action: tensor([[-9.5824, -4.7615, -3.7657,  0.8672,  0.2758, -4.8868,  4.2133]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 69
	action: tensor([[-6.0079, -0.2253, -3.1770,  3.9910, -3.6764, -5.6000, -4.7292]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 70
	action: tensor([[-9.1200, -3.8448, -2.1732,  3.3406, -4.5665, -1.3239,  0.7823]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 71
	action: tensor([[-8.4515, -6.8987, -1.7141,  2.7098, -2.8474,  6.1439,  2.4334]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 72
	action: tensor([[-8.1040,  1.0569, -4.0151,  1.9681, -3.4021,  1.2736,  0.6636]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 73
	action: tensor([[-7.6367, -8.8433, -1.4255, -2.4165, -2.6969,  2.0109,  3.3810]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 74
	action: tensor([[-9.9336, -2.1852, -3.3571,  1.1468, -7.1493, -4.5319, -1.0992]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 75
	action: tensor([[-11.5857,  -4.1676,  -1.9448,   4.3028,  -0.5086,   5.2392,   1.8803]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 76
	action: tensor([[-5.8760, -4.7156, -1.2713,  2.8539, -2.8182,  2.3914,  2.1463]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 77
	action: tensor([[-4.5572, -2.7217,  1.1632,  2.0705,  0.7556,  4.3423, -0.4470]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 78
	action: tensor([[-4.0108, -5.7191,  2.6676,  1.4972,  0.8452,  0.7884,  0.9292]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 79
	action: tensor([[-5.1583, -1.0575, -2.1054,  1.9263, -3.9507, -5.2243, -4.4866]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 80
	action: tensor([[-9.1527, -8.2003, -3.1625,  7.2457, -0.6720, -0.5859, -4.9900]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 81
	action: tensor([[-7.3600, -0.7144,  0.4124, -0.8607, -1.5434, -1.2704, -2.2807]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.6854786223739948, distance: 1.4856561926058942 entropy 2.382312461581956
epoch: 3, step: 82
	action: tensor([[-4.8006, -2.7076, -4.2700, -1.8096, -2.3567,  4.5640,  4.1129]],
       dtype=torch.float64)
	q_value: tensor([[-2.4141]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.6248193978894805
epoch: 3, step: 83
	action: tensor([[-6.2773, -2.3763,  2.8885, -0.8414,  0.0114,  2.9562,  3.6202]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 84
	action: tensor([[-7.7751, -3.9355, -1.8615,  2.1717, -3.6634, -3.3091,  0.3308]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 85
	action: tensor([[-3.3262, -0.3310, -0.8790,  5.0598, -1.8683,  2.5198,  0.7904]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 86
	action: tensor([[-4.5200,  2.4873, -1.1034, -0.1979, -5.2320,  1.7838,  5.6097]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 87
	action: tensor([[-4.4591,  1.0219, -2.1685,  0.6045, -6.8605,  3.6609,  0.8402]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 88
	action: tensor([[-4.2795, -6.4062, -2.0138, -1.9728, -3.1314,  1.0258,  4.5310]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 89
	action: tensor([[-3.1420,  0.7127, -1.6994,  2.1808, -0.9070, -2.3439,  1.6457]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 90
	action: tensor([[-3.9867, -1.0994, -1.0788, -3.5269, -2.1930,  0.4339, -0.1360]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 91
	action: tensor([[-6.8062, -0.3418, -4.5138,  9.1045, -3.1696,  1.8468,  1.5242]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 92
	action: tensor([[-3.6540, -6.6395,  2.0853,  1.4294, -6.5638, -1.7035,  3.8380]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 93
	action: tensor([[-7.8920, -5.0823, -2.7852,  0.6198, -3.1564,  2.1535,  1.6367]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.21745167213449146, distance: 1.0123070867157213 entropy 2.382312461581956
epoch: 3, step: 94
	action: tensor([[-13.5777,  -5.1017,   0.3247,  -0.9943,  -3.9527,   5.7990,  -6.5793]],
       dtype=torch.float64)
	q_value: tensor([[-2.8631]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.6194695132629064, distance: 1.456273952627385 entropy 2.786703743482861
epoch: 3, step: 95
	action: tensor([[-6.1471, -6.1059, -1.7966,  3.3998, -3.1138, -6.8168,  2.0041]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 96
	action: tensor([[-6.3555, -4.8115,  4.0587, -1.2407, -4.1784,  2.7769, -0.3340]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 97
	action: tensor([[-6.1940, -3.6548,  1.2311, -1.3317, -4.5656,  0.9653, -0.1512]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 98
	action: tensor([[-7.5562, -2.5308, -0.7555, -1.8413, -3.1771,  1.5303,  0.9348]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 99
	action: tensor([[ 0.1280, -5.3643, -1.8041,  4.0285, -1.1784, -3.6403,  6.8093]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 100
	action: tensor([[-3.3774, -3.4730, -0.9232,  1.1312, -3.1445,  1.5598,  4.9859]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 101
	action: tensor([[-8.9948, -2.9329, -4.3700,  3.4215, -2.7517,  6.4996,  1.6704]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 102
	action: tensor([[-6.4333, -4.3839, -0.5444,  2.9299, -6.8909,  2.7322,  6.3038]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 103
	action: tensor([[-10.5512,  -7.2995,  -1.0373,   5.4670,  -3.0366,   6.4785,  -3.1744]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 104
	action: tensor([[-5.8090, -2.0347,  1.2658,  0.5941, -5.0884,  2.0280,  0.8385]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 105
	action: tensor([[-5.1147, -3.0863,  1.2072,  1.0404, -2.6997,  3.0629,  0.3640]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 106
	action: tensor([[-5.7879, -3.1720, -4.4341,  6.9428, -4.6364,  3.3011, -1.6606]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 107
	action: tensor([[-10.7453,  -5.0693,  -2.6564,   1.5418,  -1.7230,   1.8005,   1.0361]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 108
	action: tensor([[-3.9646, -5.3473,  0.1918,  2.5131, -3.6139, -3.4753,  5.3538]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 109
	action: tensor([[-7.0375, -2.2059, -0.5426, -6.0438, -4.8466,  2.4070,  5.0307]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 110
	action: tensor([[-7.0341, -5.2676,  1.7769, -0.5670,  1.6488, -0.7600, -2.6856]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 111
	action: tensor([[-6.1316, -2.8259, -0.7598, -4.0584, -2.7948, -2.0599,  4.7558]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 112
	action: tensor([[-6.0786, -3.7058, -2.9270,  1.6370, -3.6244, -0.8625,  0.6006]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 113
	action: tensor([[-10.6173,  -3.8263,  -5.1892,   2.1847,  -2.4448,  -1.4804,   5.5765]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 114
	action: tensor([[-2.9312, -2.5776,  3.4951,  4.0596, -0.9552, -5.3900, -0.5127]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 115
	action: tensor([[-10.0727,  -6.7330,  -0.9332,   0.3118,  -1.8851,   3.2841,   2.1810]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 116
	action: tensor([[-5.6852, -2.2861, -0.4933,  2.1479, -4.6971,  1.9803, -2.2647]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 117
	action: tensor([[-9.3741, -6.4651, -2.4035,  7.0209, -3.0167, -3.2559,  1.9771]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 118
	action: tensor([[-7.2279, -5.0857, -0.2315, -0.7976, -3.7985, -0.0369, -0.1483]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.126581612691272, distance: 1.2146132728310903 entropy 2.382312461581956
epoch: 3, step: 119
	action: tensor([[-4.8317, -0.7633,  0.7431, -0.8641, -4.5470, -0.9734,  0.4341]],
       dtype=torch.float64)
	q_value: tensor([[-1.5466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.15122127516469863, distance: 1.0542750670738068 entropy 2.240592003086023
epoch: 3, step: 120
	action: tensor([[-4.7574, -1.1011, -1.1454,  1.0725, -1.0036,  2.8319,  0.6458]],
       dtype=torch.float64)
	q_value: tensor([[-1.4208]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.088433679474918
epoch: 3, step: 121
	action: tensor([[-5.5220, -5.4633, -1.7066,  2.2945, -1.7616, -3.1154, -2.1598]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 122
	action: tensor([[-5.4909,  1.0716, -1.4286, -1.4912, -6.2524, -1.9904, -4.9793]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.5477453819740041, distance: 0.769570122308116 entropy 2.382312461581956
epoch: 3, step: 123
	action: tensor([[-6.7024, -4.9402, -0.2629,  1.1036, -3.2073,  0.4366, -0.5402]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 124
	action: tensor([[-9.0538e+00, -2.7278e+00,  6.2970e-03,  4.1077e+00, -3.7141e+00,
          3.0296e+00,  2.5097e-01]], dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 125
	action: tensor([[-5.8105, -4.1855, -4.4321, -0.0751, -4.4437,  4.1676,  0.0639]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 126
	action: tensor([[-4.7515, -3.0963,  1.1405, -5.8621,  0.8588, -5.4209,  5.6854]],
       dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.382312461581956
epoch: 3, step: 127
	action: tensor([[-7.0521e+00, -5.7688e+00, -1.8870e-03,  2.5754e-01,  7.0841e-01,
          2.1884e-01,  1.7168e+00]], dtype=torch.float64)
	q_value: tensor([[-2.2710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.0778404307925642, distance: 1.188047838339077 entropy 2.382312461581956
LOSS epoch 3 actor 784.1038068760112 critic 2436.6953998883073
epoch: 4, step: 0
	action: tensor([[-2.6517, -4.0306, -2.9496, -0.8673, -6.5328,  2.2397,  1.9234]],
       dtype=torch.float64)
	q_value: tensor([[-1.9784]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.4099089368649325
epoch: 4, step: 1
	action: tensor([[-7.2697, -4.7602,  5.0340,  3.9014, -0.6231, -2.4321,  5.8283]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 2
	action: tensor([[-5.6023, -6.8725,  7.9145, -0.7435, -5.5010,  5.7543, -1.1021]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.19335970246119216, distance: 1.0277716890478332 entropy 2.702286843901707
epoch: 4, step: 3
	action: tensor([[-8.6215, -4.0614,  0.7544, -4.8587, -5.8258, -3.6775,  1.6847]],
       dtype=torch.float64)
	q_value: tensor([[-2.1679]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.3483090193249643
epoch: 4, step: 4
	action: tensor([[ -3.0073, -11.4700,   3.5281,   8.4984,  -1.7338,   0.7955,   7.6899]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 5
	action: tensor([[-12.9547,  -5.4222,   1.5510,   0.8337,  -7.8384,   6.4630,   0.6844]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 6
	action: tensor([[-13.4531,  -5.7964,  -4.2469,  -1.4367,  -2.4485,   0.9952,   1.5752]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.15686666051611464, distance: 1.230830773335648 entropy 2.702286843901707
epoch: 4, step: 7
	action: tensor([[-11.7514,  -3.5422,   2.4137,   6.0834,   0.8813,   1.6777,   9.6064]],
       dtype=torch.float64)
	q_value: tensor([[-4.2233]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.9486128054381857
epoch: 4, step: 8
	action: tensor([[-8.6336, -3.5416,  0.8866,  6.3737, -6.0652, -5.9545,  1.9027]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 9
	action: tensor([[-10.0941,  -7.5461,  -0.7375,   7.7660,  -3.8739,  -3.5666,   0.3902]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 10
	action: tensor([[-10.1545,  -3.7940,  -1.5117,   3.2615,  -3.7776,   0.4112,  -5.3842]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 11
	action: tensor([[-12.2305, -11.4056,  -0.4130,  -1.2020,  -3.2179,   5.4185,   9.6022]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 12
	action: tensor([[-6.1378,  3.2249, -4.0707, -2.0539, -0.0474, -1.6629,  8.3354]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 13
	action: tensor([[-8.0118,  1.2713, -3.7477, -2.4894, -1.9615,  1.4809,  2.3971]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 14
	action: tensor([[-8.9650, -3.5831,  1.1121, -1.5241, -2.7240, -0.1860,  1.2135]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 15
	action: tensor([[-8.2217, -9.6623, -0.9529, -1.8888, -1.8182, -3.6958, -1.9658]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 16
	action: tensor([[-8.0485,  2.2867, -1.4175,  0.7513,  3.2203,  5.0087,  4.3024]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 17
	action: tensor([[-9.3966, -5.1098, -1.4344,  2.5299, -3.4315,  7.1556,  9.0856]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 18
	action: tensor([[-6.6477, -7.4135, -7.3400,  2.2818,  0.5497,  1.8407, -1.9378]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 19
	action: tensor([[-7.7680, -8.2813,  5.3070, -2.4241, -4.1749, -0.7838,  5.3308]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 20
	action: tensor([[-15.8035,  -0.8535,   0.7201,   2.7154,   0.3159,   0.9546,   2.4470]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 21
	action: tensor([[-7.7971, -7.3258, -1.6213,  3.5762, -2.8393,  3.3419,  7.2744]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 22
	action: tensor([[-7.7798, -1.4450,  2.9925, -0.5714, -4.4746,  0.7098, -0.2517]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 23
	action: tensor([[-4.0898, -3.7895,  0.3107, -0.1081, -4.9166,  1.4490,  3.7758]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 24
	action: tensor([[-11.4247,   0.0552,  -5.1661,   8.2335,  -0.4471,  -2.4707,   4.3997]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 25
	action: tensor([[-10.9092,  -6.0056,  -0.2103,   2.5682,  -0.4756,   0.7421,  11.5044]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 26
	action: tensor([[ -6.8694,  -4.9018,  -0.5911, -15.3807,  -5.7997,   7.0003,   2.3833]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 27
	action: tensor([[-6.7442,  3.3652, -3.4558,  5.1809,  1.5841,  2.4488,  6.1275]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 28
	action: tensor([[ -9.3378, -12.3193,   2.1399,  -1.8278,  -5.0103,  -0.5604,   1.1186]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 29
	action: tensor([[-8.5297, -1.6935,  0.3035,  4.1546, -3.4794,  2.7720, -1.8036]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 30
	action: tensor([[-12.6384,  -9.6606,   4.2735,   7.4729,  -7.9199,  -3.5448,   2.0216]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 31
	action: tensor([[-9.1120, -6.3525,  1.8332,  0.6995, -0.6780, -2.7296, -3.2093]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 32
	action: tensor([[ -8.3964,  -3.0406,   1.3921,   4.0392,  -6.4147, -10.8007,  -1.4107]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 33
	action: tensor([[-3.8539, -2.1271, -5.4064, -1.1717, -4.2398, -0.2260, -0.0883]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 34
	action: tensor([[-5.8189, -3.2526, -2.5232, -0.3686, -3.6298, -4.1040,  5.0132]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 35
	action: tensor([[-12.3376,  -2.3019,  -0.3711,   4.7423,   1.2377,  -4.7818,   1.5514]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 36
	action: tensor([[-1.0272e+01, -5.9804e+00, -1.5989e+00, -8.9873e-03, -3.2526e+00,
          8.6256e+00, -3.7063e+00]], dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 37
	action: tensor([[-8.6493, -6.2128,  2.7660, -0.9107, -1.9780, 11.4102, -1.9178]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 38
	action: tensor([[-9.6399, -3.9282, -0.8986,  8.6980,  0.4306,  0.3921, -0.2511]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 39
	action: tensor([[-5.5013, -3.4592,  7.0084,  2.5755, -0.5074, -1.4136,  1.6265]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 40
	action: tensor([[ -9.3266, -12.2340,   2.7388,   8.2803,  -6.8627,   0.4746,   1.6756]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 41
	action: tensor([[-9.3400, -2.3354, -2.4879,  9.8133, -7.0263,  8.7809,  9.8253]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 42
	action: tensor([[-9.7342,  2.9469, -2.1282, -1.0951, -5.2409, -7.6965,  1.5377]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 43
	action: tensor([[-10.0203,  -6.1026,   1.1209,  -1.1470,   1.9100,  -4.3251,  -1.7517]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 44
	action: tensor([[-3.6770, -7.3410, -3.8764,  6.1801, -0.2929,  4.2289, -2.2788]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 45
	action: tensor([[-9.9917, -2.4782,  4.6804,  4.2731, -6.6446, -0.4532,  6.8779]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 46
	action: tensor([[-9.2371, -8.0458, -2.3543, -1.3954, -0.0147, -2.4298,  1.2888]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 47
	action: tensor([[ -9.5969, -11.0614,  -6.2348,   4.2370,  -4.7261,   6.2342,   6.9134]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 48
	action: tensor([[-8.9076, -3.0564,  0.1886,  5.8307, -3.4326,  4.7616, -0.9522]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 49
	action: tensor([[-5.0866, -5.8701,  0.2595, -0.6403, -0.7750, -3.1050,  8.6768]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 50
	action: tensor([[-1.1580e+01, -4.9385e+00,  3.4021e-03,  2.6194e+00,  4.7404e-01,
         -4.0048e+00, -3.0260e+00]], dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 51
	action: tensor([[-7.6232, -3.5269, -3.4969,  1.7236, -4.6334,  6.1702,  7.5088]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 52
	action: tensor([[-8.7612, -8.5746,  2.5023,  8.9482, -0.1374,  8.1143,  1.9784]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 53
	action: tensor([[-14.8797,  -4.3152,  -3.3503,   2.8913,   0.4397,   5.1680,  -2.0753]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 54
	action: tensor([[-10.1702,  -0.8835,  -1.5690,   3.1497,  -5.8926,   5.7214,   6.8509]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 55
	action: tensor([[-9.4242, -2.4765, -0.8314, -3.8669, -4.6260, -6.7658,  0.6046]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 56
	action: tensor([[-7.0082,  0.4827,  2.4920,  1.2318, -2.6883,  0.0583,  0.0478]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.01547287928294816, distance: 1.1531634207257468 entropy 2.702286843901707
epoch: 4, step: 57
	action: tensor([[-16.3764, -12.5441,  -1.5311,   3.2170,  -6.0022,  -4.5607,  17.3443]],
       dtype=torch.float64)
	q_value: tensor([[-3.7765]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.9800151101095316
epoch: 4, step: 58
	action: tensor([[-7.6830, -4.6400,  1.8147,  4.0786, -2.7719,  5.9753,  0.1821]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 59
	action: tensor([[-4.6193, -3.8490, -3.9307,  2.6824, -1.6250,  1.8002,  1.4818]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 60
	action: tensor([[-7.5178,  2.6863, -3.9923, -2.7753, -6.7249,  2.9844,  8.8881]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 61
	action: tensor([[-12.8543,  -3.8093,   0.3666,   4.2667,  -1.2796,   4.4630,  12.4683]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 62
	action: tensor([[-10.2311,  -9.1230,  -4.0972,   4.8760,  -7.4001,   1.3822,   8.4941]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 63
	action: tensor([[-9.1013, -2.8914, -3.2709,  4.0443,  1.7571, -8.0527,  3.0643]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 64
	action: tensor([[-14.8700,   2.3250,   0.9340,  -1.6811,  -4.6638,  -2.5125,   5.9712]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 65
	action: tensor([[-9.9233, -2.4577, -5.8438, -0.7097, -2.4132,  3.7671, -2.1111]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 66
	action: tensor([[-8.7088, -3.7428,  4.6678, -7.3528,  0.4879,  1.2876,  0.6530]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 67
	action: tensor([[-7.4233, -1.6345,  1.7126,  0.6577, -2.4503,  0.6101, -2.9507]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 68
	action: tensor([[ -6.2388, -10.2927,   1.2078,  -7.0275,   1.2184,  -2.1542,   3.7502]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 69
	action: tensor([[-10.8962,  -1.8675,  -0.7373,   5.8609,  -5.6572,   2.2680,   3.4881]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 70
	action: tensor([[-10.7966,  -6.2861,   3.4064,   1.6839,  -0.4311,   1.0080,   9.2929]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 71
	action: tensor([[-6.9011,  0.1078, -2.1613, -2.2733,  0.1244,  1.1678, -3.6712]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 72
	action: tensor([[ -8.3640, -11.0327,   5.7929,   1.3657,  -2.9119,   0.1876,  -0.7589]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 73
	action: tensor([[-5.0405, -4.0884, -0.2373, -0.5722, -2.6806,  0.3477,  2.9734]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 74
	action: tensor([[-12.5040,  -4.7503,  -0.5317,  10.1903,  -5.4383,  -0.3438,   1.2665]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 75
	action: tensor([[-10.3120,  -3.2911,  -6.4226,  -4.7005,  -3.9872,   6.0088,   5.5309]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 76
	action: tensor([[-11.7580,  -3.5458,   1.2784,   0.7237,  -1.7754,   1.4493,  10.7299]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 77
	action: tensor([[-8.3244, -8.2420,  0.7781,  3.6867, -5.9753,  7.1816, -7.7642]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 78
	action: tensor([[-12.8446, -11.2553,  -3.1280,  -1.8224,  -4.7746,   9.1972,   2.9496]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 79
	action: tensor([[-9.4090, -4.4032, -6.5585, -4.1511, -3.0696,  3.9670,  3.1136]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 80
	action: tensor([[-13.2225,  -1.2015,  -6.3962,   2.4542,  -4.0766,   3.5124,  -1.5831]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 81
	action: tensor([[-11.9010,  -4.9363,   4.1676,  -4.7877,  -6.1195,  -2.1146,   5.2953]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 82
	action: tensor([[-9.5802e+00, -2.8690e+00,  8.5017e-01, -1.3879e-03, -2.2243e+00,
          5.4133e+00, -6.2094e+00]], dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 83
	action: tensor([[-6.8713, -7.3621, -3.0698, -2.0711, -2.3172, -4.0779,  3.6346]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 84
	action: tensor([[-7.7002, -2.5677,  1.1231,  1.4672, -3.4512, -2.5457, -1.3688]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 85
	action: tensor([[-8.0846, -0.2295, -3.0027,  2.2194, -2.4121, -2.0128,  4.7166]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 86
	action: tensor([[-10.9255,  -5.1951,   6.6560,   5.4149,  -6.6629,   0.6851,   5.2248]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 87
	action: tensor([[-6.8114, -8.4184,  6.2832,  0.2447, -0.8219,  3.7660, -1.4438]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 88
	action: tensor([[-10.8617,  -5.3479,  -3.4720,   4.0770,  -5.2192,   3.2056,  -2.5583]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 89
	action: tensor([[-7.2431, -1.5502,  1.1555, -0.2990, -6.5131, -6.1969,  2.4545]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 90
	action: tensor([[-6.4576, -3.5856, -0.7280, -5.7843, -5.1719, 15.4594, -4.7581]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 91
	action: tensor([[-7.8517, -6.5142,  0.2400,  0.7783, -1.9123, -0.3260, -2.3368]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -1.1614667317805294, distance: 1.682406629481987 entropy 2.702286843901707
epoch: 4, step: 92
	action: tensor([[-10.5421,  -5.1929,   7.4063,  -1.1530,   1.1127,   6.9897,  -3.1062]],
       dtype=torch.float64)
	q_value: tensor([[-3.8744]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.0264650535112634
epoch: 4, step: 93
	action: tensor([[-11.8400,  -8.4084,  -2.9010,   2.4230,  -2.8178,  -7.1322,   3.3118]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 94
	action: tensor([[-7.4630, -4.6970,  0.6126,  2.1401, -1.0901, -1.5119,  3.4397]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 95
	action: tensor([[-9.6770, -4.6128, -0.5506, -1.1298, -1.1616,  4.0632, -1.9800]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 96
	action: tensor([[-5.7309, -2.2744, -2.0985,  6.9298, -6.3476,  1.8695,  3.0621]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 97
	action: tensor([[-2.6332, -0.5767, -7.5655, -2.5065, -6.5787,  9.6994,  4.3044]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 98
	action: tensor([[-5.4147, -6.1437, -3.1775, -0.9148, -3.9332, -6.8666,  0.5945]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.9922179543881433, distance: 0.10094936216188126 entropy 2.702286843901707
epoch: 4, step: 99
	action: tensor([[-8.0943, -5.7183, -6.1650,  2.3279, -4.1082,  2.2689,  2.5889]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 100
	action: tensor([[-10.2788,  -3.6311,  -1.3733,   3.1083,  -4.5085,   7.5666,   5.1067]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 101
	action: tensor([[-10.8258,  -6.2515,   2.3308,  -0.8723,  -2.8584,  -9.9491,  -2.7172]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 102
	action: tensor([[-13.3375,  -3.4297,  -0.4651,   0.9172,  -6.0250,   4.4685,   1.7852]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 103
	action: tensor([[-12.4588,   0.5137,  -1.1932,   1.8218,  -2.2396,  -0.5455,   1.5613]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.05347920959527186, distance: 1.1745450472066037 entropy 2.702286843901707
epoch: 4, step: 104
	action: tensor([[-5.2586, -5.9899, -8.9036, -2.2186, -2.7712,  1.2786,  1.6538]],
       dtype=torch.float64)
	q_value: tensor([[-3.5850]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.9784051407469305
epoch: 4, step: 105
	action: tensor([[-9.4349, -8.4059,  0.6117, -3.1903, -4.0399,  1.8393, -1.9353]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 106
	action: tensor([[-8.0174, -5.9442,  3.4304, -3.4693, -8.4214,  1.9094,  3.1089]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 107
	action: tensor([[-9.8531,  0.3505,  1.0063,  6.9155, -0.8951, -1.3385, -3.4423]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 108
	action: tensor([[-12.1000,  -1.4816,  -2.4775,   4.2807,  -0.0994,   1.9852,  -6.8723]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 109
	action: tensor([[-7.4124, -5.2604, -1.1010,  8.9613, -2.5976, -3.7582,  4.5999]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 110
	action: tensor([[-7.5307,  2.3837,  6.8870,  3.0828, -0.5848,  2.9227,  3.0989]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 111
	action: tensor([[-5.4924,  1.1635,  3.7681,  2.2831, -1.9917,  4.1983,  2.0459]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 112
	action: tensor([[-9.8550, -2.1331,  0.7093, -0.5550, -6.2871, -2.4149,  8.7144]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 113
	action: tensor([[-8.2280, -3.0685,  0.5695,  6.8447, -3.4882, -2.5449,  7.0177]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 114
	action: tensor([[-6.8724, -3.7094, -5.3231,  4.0634, -3.0942, -3.5129, -5.0070]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 115
	action: tensor([[-6.6612, -8.6566, -9.2784,  3.6660, -0.5572,  1.0586,  1.1236]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 116
	action: tensor([[-8.8891, -1.9456, -0.8391,  1.6573, -4.5095,  5.8976,  0.6348]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 117
	action: tensor([[ -8.2810,  -4.1459,  -1.6956,  -3.0911,  -4.2452, -10.0825,   7.0146]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 118
	action: tensor([[-5.3490, -2.4332, -2.7812, -0.0724, -6.9682,  7.7916,  2.9087]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 119
	action: tensor([[-11.0594,  -2.3697,  -3.9815,   2.5515,  -4.4037,  -2.9171,   3.3936]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 120
	action: tensor([[-14.2184,  -0.3359,   1.4251,   1.5784,  -8.6332,   5.4148,   7.6587]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 121
	action: tensor([[ -6.4063,  -0.9615,  -3.3558,  -3.6187, -12.5515,  -6.2233,  -1.2866]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 122
	action: tensor([[-7.1537, -0.8858,  1.9196, -1.5850, -1.3788, -7.6683,  0.7234]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.8100703231409503, distance: 1.539587644966817 entropy 2.702286843901707
epoch: 4, step: 123
	action: tensor([[ -8.9033,  -6.7494,  -4.2257, -10.0429,  -3.5736,  -1.3014,   0.9268]],
       dtype=torch.float64)
	q_value: tensor([[-3.5379]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.87531664279413
epoch: 4, step: 124
	action: tensor([[-11.3316,   6.2535,  -1.1599,   4.2407,  -0.5119,  -2.0728,   2.2378]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.530801036040554, distance: 0.7838540661018859 entropy 2.702286843901707
epoch: 4, step: 125
	action: tensor([[ -3.7119, -10.5927,  -6.4826,  -0.6014,  -9.2030,  -3.4403,   6.7683]],
       dtype=torch.float64)
	q_value: tensor([[-3.8203]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998657638623469
epoch: 4, step: 126
	action: tensor([[-7.7907, -5.5009, -3.9941,  6.3721,  0.0093, -3.9090,  6.8653]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.702286843901707
epoch: 4, step: 127
	action: tensor([[-6.7532, -0.0090,  3.1142,  1.6787, -7.3353, -0.9426,  0.6182]],
       dtype=torch.float64)
	q_value: tensor([[-3.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.6433552344746767, distance: 1.4669740095963222 entropy 2.702286843901707
LOSS epoch 4 actor 736.1093649081903 critic 2169.5802907813
epoch: 5, step: 0
	action: tensor([[-15.3258,  -7.6186,  -4.5803,   7.3928,  -5.7553, -10.8494,   9.4043]],
       dtype=torch.float64)
	q_value: tensor([[-5.3642]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2091016639852126
epoch: 5, step: 1
	action: tensor([[-9.5036, -4.5525,  2.4539,  2.4729, -5.4742, -2.7823, 10.4170]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 2
	action: tensor([[-11.2742,  -5.0796,   2.5754,   8.6811,  -3.4246,   1.1179,  -0.1693]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 3
	action: tensor([[-1.1196, -2.2203,  0.0377,  2.2946, -5.9616,  0.9807,  7.4006]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 4
	action: tensor([[-1.8654, -2.9999, -1.2715,  3.1678, -4.0217, -2.7620, -0.5581]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 5
	action: tensor([[ -3.6816,   0.0397, -10.7724,   5.7918,  -4.4981,   4.0061,   4.9356]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 6
	action: tensor([[ -8.7095, -10.0640,  -2.3956,  -2.3540,  -2.2994,   8.6744,   6.8186]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 7
	action: tensor([[-13.3581, -11.9597,  -3.9245,   7.5171,  -5.4645,  -5.5138,   5.7811]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.12007352721640552, distance: 1.2110998761044036 entropy 2.998170092159314
epoch: 5, step: 8
	action: tensor([[-18.0054,  -0.9991,   3.5012,   5.5860,  -4.4667,   6.9714,   0.2290]],
       dtype=torch.float64)
	q_value: tensor([[-3.7412]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.39261254526874945, distance: 0.8918454521834741 entropy 2.916457858512806
epoch: 5, step: 9
	action: tensor([[-14.3556, -11.3779,   3.0614,  -3.9521,  -7.3198,   4.2800,   7.1895]],
       dtype=torch.float64)
	q_value: tensor([[-4.7371]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.1591036696287986
epoch: 5, step: 10
	action: tensor([[-15.4727, -14.2154,  -1.9952,  -2.3892, -10.8004,  -4.4711,   3.9096]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 11
	action: tensor([[-4.6693, -9.1133, -5.7458,  9.7171, -5.2212,  3.5521, -5.4041]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 12
	action: tensor([[-5.5470, -1.5927, -7.8062,  4.1473, -1.2627,  4.6753, -1.2197]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 13
	action: tensor([[-11.5703,  -2.2630,  -0.6773,  -8.2355,  -4.5428,   0.8845,   0.3214]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 14
	action: tensor([[-10.1116,  -5.8788,  -4.6396,  -1.7473,  -4.0609,   6.2837,   1.3702]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 15
	action: tensor([[-13.9604,  -3.6672,  -1.7810,   2.9378,  -3.7827,   3.1145,   3.4981]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 16
	action: tensor([[-11.7332,  -7.1976,   4.8681,   0.0783, -17.0539,   5.5546,  -4.6360]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.43233259607984165, distance: 1.369552329593166 entropy 2.998170092159314
epoch: 5, step: 17
	action: tensor([[-18.2214,   2.2766,  -1.5688,  -1.5330,  -6.9982,   6.6329,   7.5826]],
       dtype=torch.float64)
	q_value: tensor([[-4.6223]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.0330191936474136
epoch: 5, step: 18
	action: tensor([[-11.2126,  -8.4412,  -0.6236,   5.6065,  -8.3362,  -6.7224,   8.3593]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 19
	action: tensor([[-6.6303, -3.7918, -1.2303,  7.5199, -8.1205, -1.3737, -3.9586]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 20
	action: tensor([[-6.3157, -6.9505, -2.7475, -1.4069, -4.2671, 10.9751,  8.1603]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 21
	action: tensor([[-9.1481, -7.6947,  4.3079, -3.0104, -3.6966,  4.2079,  6.9175]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 22
	action: tensor([[-5.5483, -8.6297,  0.4045,  4.2918, -9.9675,  4.5433,  0.7194]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 23
	action: tensor([[-5.9397,  1.9145,  3.1767, -7.9777,  2.1692, -0.3418, -3.1926]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 24
	action: tensor([[-12.6073,  -0.2905,  -1.2815,  -3.0973,  -5.1353,  -8.4953,   5.8537]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 25
	action: tensor([[ -3.1090,  -4.5970,  -0.5311,   4.0730,  -3.1001, -14.1406,   0.0509]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 26
	action: tensor([[-14.0702,  -6.6758,   2.1527,   3.8748,  -5.1570,   0.3407,  10.5045]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 27
	action: tensor([[-6.3179,  0.4993,  1.5660,  7.8576, -0.3704, -6.6487,  5.0398]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 28
	action: tensor([[-11.4718,  -0.4847,  -1.5318,   0.7576,  -3.8382, -10.9439,  -1.6839]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 29
	action: tensor([[-16.2097, -10.6904,   6.9738,   2.6902,  -4.1930,   5.5213,   1.8163]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 30
	action: tensor([[-11.7166,  -9.4180,   0.0570,  -3.6614,  -1.0808,   4.8636,   3.8952]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 31
	action: tensor([[-9.2603, -8.8146,  1.8335, -3.5674, -4.4237, 10.3443,  7.7806]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 32
	action: tensor([[-13.2137, -10.6921,  -2.8314,   3.6965,  -9.7533, -10.0734,   0.8787]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 33
	action: tensor([[-11.0726,  -8.2677,   1.7458,  -2.1483,  -4.0541,  -0.7093,   1.0004]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 34
	action: tensor([[-9.7855, -9.3787,  4.6807,  1.7072, -5.1661,  4.2007,  4.0707]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 35
	action: tensor([[-10.3184,  -5.1011,   1.0834,   1.3474,  -6.3265,  -1.6300,   6.2091]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 36
	action: tensor([[-9.2515, -5.8681, -9.3398,  4.3426,  2.0077,  7.0994, -7.3434]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 37
	action: tensor([[-11.1084,  -1.0395,  -3.4999,   1.0501,  -3.1856,   0.8480,  -0.5766]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.7715785068853567, distance: 1.523129727939578 entropy 2.998170092159314
epoch: 5, step: 38
	action: tensor([[ -8.1532, -11.2267,  15.9195,  -6.3918,  -8.3892,  13.7281,  10.1472]],
       dtype=torch.float64)
	q_value: tensor([[-5.5035]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.174235171072276
epoch: 5, step: 39
	action: tensor([[ -7.2945,  -8.1177, -10.8764,   2.0240,  -8.7112,  -3.4746,   4.3870]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 40
	action: tensor([[ -8.2206, -10.1355,   3.3894,   2.3238,   0.7766,   4.2649,   4.1197]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 41
	action: tensor([[-16.0180,  -8.8109,  -4.6087,   3.1300,  -3.9964,  -3.8699,  10.8393]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 42
	action: tensor([[-8.8408, -1.0982,  4.7884,  0.7173, -7.7263, -0.7167,  0.8433]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 43
	action: tensor([[-9.2467, -2.9291, -0.2205,  8.8869,  7.5868, -1.0386,  4.1419]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 44
	action: tensor([[-7.1717,  2.5221,  9.4844, -3.0192, -1.7876, 13.8938, -0.7137]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 45
	action: tensor([[-7.6345, -1.3914, -1.7297,  1.4227,  1.4793, -4.8197,  0.1440]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 46
	action: tensor([[ -5.5744,  -3.5273,  -6.2716,   2.4881,   0.4236, -16.3896,   3.6521]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 47
	action: tensor([[-14.0856,  -4.4418,   2.9411,   3.1081,  -6.6938,   3.4691,   2.2949]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 48
	action: tensor([[-11.7802,  -5.2453,  -4.2744,   2.8998,  -5.5841,  11.4834,   7.8131]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 49
	action: tensor([[-11.0084,  -5.0177,  -3.8279,   3.6896,  -1.9022,  -2.0440,   1.8827]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 50
	action: tensor([[-1.6518, -1.2815, -4.9114,  1.6008, -4.1652,  8.5481,  2.5482]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 51
	action: tensor([[-7.4954,  0.7922,  2.7637,  6.5651,  0.8240,  8.8213,  2.3120]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 52
	action: tensor([[-7.5542, -7.1926, -5.6039, -4.2894,  0.2667,  0.3523,  4.2344]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 53
	action: tensor([[-12.3931, -12.4940,  -4.3971,   9.0717,   0.0967, -10.0838,  -4.0540]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 54
	action: tensor([[-13.2782,  -0.3381,   3.0178,  -0.4433,  -1.5824,   5.2784,   8.0942]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 55
	action: tensor([[-10.4505,  -0.9919,   4.5004,   0.8326,   2.2021,  -0.8013,   2.1725]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 56
	action: tensor([[-11.2846,   0.4413,  -0.0583,   9.4066,   0.2130,  -2.4883,   3.3829]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 57
	action: tensor([[-10.6011,  -6.8733,  -3.3881,   0.0867,  -0.5179,  -7.3758,   1.6305]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 58
	action: tensor([[-15.9919,  -7.1913,  -0.2153,   2.3853,  -3.2129,  13.2029,   3.9803]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 59
	action: tensor([[-16.0074,  -4.2108,  -4.7450,  -0.0812,  -1.9191,   1.0866,   2.7367]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 60
	action: tensor([[-9.8870, -3.1680, -2.5276,  9.1461,  0.0721,  5.1740,  4.1144]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 61
	action: tensor([[ -2.2274,  -3.8582,  -4.1705,   6.5798,  -2.7385,  -3.3977, -11.0988]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 62
	action: tensor([[-5.1509, -3.9834,  2.9170, -2.0461, -2.3693,  7.6622,  6.7440]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 63
	action: tensor([[-11.0443,  -3.7549, -10.4446,   4.9690,  -8.8736,  -0.2744, -10.1835]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 64
	action: tensor([[-12.8313,   5.2521,   1.3903,   3.7961,  -1.2308,  -0.6487,   0.9844]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 65
	action: tensor([[-12.3420,  -6.7399,  -0.3700,  -0.8799,   2.1151,   1.4470,   2.2391]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.29383186333167266, distance: 0.9616360859275255 entropy 2.998170092159314
epoch: 5, step: 66
	action: tensor([[-11.8123,   1.1958,   3.1341,   7.8936,  -5.5117,  -5.5176,   1.6147]],
       dtype=torch.float64)
	q_value: tensor([[-4.0910]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.0367585359276794
epoch: 5, step: 67
	action: tensor([[-10.1839,  -0.8731,   6.8624,  -6.3196, -12.7349,   3.2170,   4.4220]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 68
	action: tensor([[-5.5322, -4.6374,  1.2653,  0.1917, -5.7485,  9.8038, -5.0676]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 69
	action: tensor([[-12.4543,  -7.3037,  -5.9757,  -1.8153,  -7.1883, -10.2198,  10.3388]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 70
	action: tensor([[-14.1219,  -6.5488,  -3.9799,  -0.2549,  -6.2546,   4.0714, -11.1002]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 71
	action: tensor([[-12.8063,  -5.2675,  -2.7395,  -2.1615,  -0.5892,  -3.8992,   7.0174]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 72
	action: tensor([[ -6.9170, -10.8033,   6.7240,   0.4374,  -3.5950,   2.5025,  -5.2910]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 73
	action: tensor([[-12.6478,  -0.2239,  -6.5854,  10.0169,  -2.6738,   0.6761,   1.1024]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 74
	action: tensor([[ -3.6538,  -3.0660,   6.1734,   0.4904, -11.1320,  -6.4148,   5.7993]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 75
	action: tensor([[-13.9068,  -3.6991,  -3.3871,   0.3959,   0.3544,   3.0688,   2.5720]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 76
	action: tensor([[ -4.7358, -12.0621,  -6.8767,  -5.3722,  -0.7258,  -8.5935,   1.5712]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 77
	action: tensor([[-5.9432, -9.1157, -3.8397,  4.0331, -2.2709,  4.5584, 12.6951]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 78
	action: tensor([[-12.3891,  -2.8266,  -3.5605,   2.7837,  -7.9609,  -4.5189,   3.9085]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 79
	action: tensor([[-8.2217, -8.9688,  3.8085, -6.4205,  0.8510,  5.6253,  7.8883]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 80
	action: tensor([[-9.1490,  2.7333,  4.1609, -2.3914, -2.5101,  5.7019,  7.7421]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 81
	action: tensor([[-13.5828,  -2.3694,  -8.3364,  -3.2656,  -5.1240,   7.6872,   5.8331]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 82
	action: tensor([[ -7.3906,  -5.4951,  -3.3475,   6.7990,  -6.4270, -10.7081,  -5.8886]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 83
	action: tensor([[ -6.4463, -14.3997,   5.0644,   0.8185,  -3.0420,  -1.7703,  -6.8438]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 84
	action: tensor([[-15.5358,  -4.8191,   3.7708,  -1.0806,  -5.2433,   5.0659,  -1.7790]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 85
	action: tensor([[ -7.8749,  -5.7882,  -5.1911,   0.3236, -10.2988,  -7.2292,   1.3127]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.33144539304765064, distance: 1.320439090934088 entropy 2.998170092159314
epoch: 5, step: 86
	action: tensor([[-14.3791,  -8.6213,   1.0210,  -4.7039,  -3.4958,   9.2936,  -8.8576]],
       dtype=torch.float64)
	q_value: tensor([[-4.4343]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.088979330336284
epoch: 5, step: 87
	action: tensor([[-11.7017, -13.5337,  -1.2915,  -0.8961,  -2.2445,  -1.7690,   5.7930]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.3119325900656178, distance: 0.9492315996718279 entropy 2.998170092159314
epoch: 5, step: 88
	action: tensor([[-21.5270,  -3.9362,  -7.5417,  -3.4465,  -5.7414,   2.2157,  13.6030]],
       dtype=torch.float64)
	q_value: tensor([[-6.1425]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2929751290161766
epoch: 5, step: 89
	action: tensor([[-15.0099,  -5.5359,   1.1051,  -1.1242,  -2.0898,   4.7153,   2.0915]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 90
	action: tensor([[ -9.7418,  -4.7331,   0.2393,   5.7337, -10.6138,  -0.8760,  -1.7363]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 91
	action: tensor([[-17.4641,   1.8165,  -5.8659,   1.3200,  -4.0004,   4.6999,   3.5401]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 92
	action: tensor([[-11.4301,  -5.3136,   5.7681,   7.1139,  -2.7473,   0.4916,   9.1378]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 93
	action: tensor([[-6.5820, -8.2970,  2.1497, 14.6288, -1.6078,  2.3176,  6.5999]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 94
	action: tensor([[-14.0082,  -9.6909,  -2.8131,   2.9165,  -2.5131,  -2.6858,   5.4861]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 95
	action: tensor([[-10.5782,  -3.6960,  -6.5272,   6.0641,  -3.6727,  -0.2228,   8.3903]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 96
	action: tensor([[-10.1060, -10.7414,  -2.4217,   5.8427,   3.8155,  -1.5501,   9.1296]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 97
	action: tensor([[-7.3611, -5.1606,  0.7617, -5.8600,  7.6843,  3.9217, -1.3892]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 98
	action: tensor([[-8.2214, -3.4232,  4.5235, -3.1803, -9.0297, -2.1500,  1.6543]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 99
	action: tensor([[-10.8415,  -5.7318,  -5.3020,   8.1196,   1.3662,  -9.3748,   5.8291]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 100
	action: tensor([[-9.5478,  5.4965, -5.2698,  5.3542, -1.9571,  8.6016, -7.0547]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 101
	action: tensor([[-10.4674,  -1.1468,   5.7082,   4.2787,  -3.5619,  -3.0775,  -4.6294]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 102
	action: tensor([[-6.7931,  3.6986,  1.0161,  7.3432, -2.6454, -6.9160, -9.6540]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 103
	action: tensor([[-10.7620,  -4.3354,   0.5757,   4.7921,  -5.9310,   0.9982,  11.0916]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 104
	action: tensor([[-8.5617, -5.6752, -0.3310,  3.5831,  2.7589,  2.2334,  3.3028]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 105
	action: tensor([[-11.7605,  -7.6906,   0.8835,  -7.6068,  -4.6732,  -3.0080,  -9.5052]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 106
	action: tensor([[-11.5731,  -8.3738,  -5.1768,  11.6085,   1.1757,   1.5340,   3.1101]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 107
	action: tensor([[-16.4974,  -6.2539,  -4.2146,  -9.5828,  -7.2183,  -3.5419,   4.1497]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 108
	action: tensor([[-12.2028,  -1.9225,   1.5668,  -1.4254,  -6.2951,  -5.2395,   8.2950]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 109
	action: tensor([[-10.6102,  -5.8690,  -3.4560,   8.5323,   0.7349,   3.4116,   9.3287]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 110
	action: tensor([[-2.6346, -6.4904,  2.7496,  4.7192, -2.3372,  2.5759, -5.7480]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 111
	action: tensor([[-11.5117,  -2.8945,   5.0523,   1.6782,  -5.4744,   4.0215,   7.6223]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 112
	action: tensor([[-6.5310, -4.1634, -7.8120,  3.2353, -5.4890,  9.0850, -3.4165]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 113
	action: tensor([[-8.9927,  4.9079,  3.0497,  6.1511,  5.9806, -0.9649, -1.6077]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 114
	action: tensor([[ -9.3849, -10.2890,  -7.0257,   3.3590,  -6.2430,   4.3957,   6.6960]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 115
	action: tensor([[-8.5231, -3.5988, -0.7309,  4.7758, -6.7449,  0.1322, 10.8517]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 116
	action: tensor([[-16.3119,  -4.3211,  -2.0086,   4.4499,   3.8041,  15.6380,  -1.0646]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 117
	action: tensor([[-11.8047,  -3.2708,  -5.4456,   5.3847,  -4.5152,   4.3991,  -0.7667]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 118
	action: tensor([[ -7.4619, -12.7578,   0.8580,   2.9555,  -8.4994,   3.2466,   0.7903]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 119
	action: tensor([[-12.2794,  -4.8307,   1.4720,  -2.7980,  -6.5439,  -3.3943,  10.6857]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 120
	action: tensor([[-11.5908,  -3.1244,   4.5233, -14.8554,  -0.4382,  -5.3479,  -0.2961]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 121
	action: tensor([[-10.1511, -15.6951,   2.8994,   0.0725, -11.3476,   8.7228,   3.4088]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 122
	action: tensor([[-12.1541,  -7.4943,   5.8322,   6.9958,  -5.3725,   0.3442,   6.3259]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.08269799401534783, distance: 1.1907219493629668 entropy 2.998170092159314
epoch: 5, step: 123
	action: tensor([[-3.8280, -3.9796,  0.7439,  1.3303,  0.0098, -0.2427,  0.4059]],
       dtype=torch.float64)
	q_value: tensor([[-2.7057]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.610174474314556
epoch: 5, step: 124
	action: tensor([[-6.0998, -1.2201,  5.7949,  8.9702, -3.9484, -1.7932, -8.9632]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 125
	action: tensor([[-14.5697,   5.2251,   6.5323,  -3.0754,   5.6768,  16.6318,  -0.1587]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 126
	action: tensor([[-8.9916,  0.7978, -2.5120, -6.8284, -0.2796, 12.3413,  4.0017]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 2.998170092159314
epoch: 5, step: 127
	action: tensor([[-12.2395,   0.4159,  -8.3587,   0.3249,  -6.6575,  -1.4331,   6.6676]],
       dtype=torch.float64)
	q_value: tensor([[-5.9698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.8920823432145989, distance: 0.375926504708875 entropy 2.998170092159314
LOSS epoch 5 actor 605.7035693748055 critic 1916.1053663032098
epoch: 6, step: 0
	action: tensor([[-13.3083,  -5.2822,  11.3569,   7.1167, -13.1095,  -9.6802,  -9.0715]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 1
	action: tensor([[-19.7868, -17.6546,   5.2161,  -6.3377,  -7.2217,   1.5243,  10.8750]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 2
	action: tensor([[-13.5484,  -6.7386,  -3.6978,   8.2955,   3.6314,  -0.3230,  -4.6612]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.08306137856511253, distance: 1.0957887213896287 entropy 3.2771571577000884
epoch: 6, step: 3
	action: tensor([[-14.9029,   1.2991,   7.0354,  -3.7869,  -9.8974,  16.1037,  -4.8212]],
       dtype=torch.float64)
	q_value: tensor([[-10.1315]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.7521966682059955
epoch: 6, step: 4
	action: tensor([[-14.2587, -12.1006,   4.4309,  12.1873,  -7.8659,  -7.2124,  -1.7969]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 5
	action: tensor([[-7.4022,  9.9579, -8.3096, -5.1546, -5.9584, 15.1978,  1.7515]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 6
	action: tensor([[-15.4438, -12.1850,   2.0248,   1.1677,  -5.0899,   5.8731,  -3.7846]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 7
	action: tensor([[-12.8850,  -9.5212,   4.6052,  17.9745,   1.9310,   0.5681,   3.5677]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 8
	action: tensor([[ -7.1365, -12.8543,  -5.8392,  11.6997, -15.2667,   4.8984, -13.8459]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 9
	action: tensor([[-14.6091,   0.9069,  -6.6274,   5.9677, -11.4173,  -4.1014,   8.2662]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 10
	action: tensor([[-21.8404,   4.0676,   9.3720,   5.2960,  -4.4976,   6.1383,   9.6589]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 11
	action: tensor([[-23.3042,  -9.3109,  -6.9768,  17.9154,  -5.8664,  15.0083,   2.0473]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 12
	action: tensor([[-10.4114,   1.7989,   5.5861, -16.9678,  -3.2176, -16.4361,   9.6080]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 13
	action: tensor([[-16.2618,  -6.6235,   9.4007,  10.1117,  -3.6221,  -9.8502,   3.6088]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 14
	action: tensor([[-14.0331, -12.7105,  -6.5743,   0.1572,  -5.6160,   3.0413,   2.9830]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 15
	action: tensor([[-10.6037,  -9.9005,   7.9251,   6.3633,  -4.3215,  -3.6786,   2.5692]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 16
	action: tensor([[-6.6843, -7.4856,  2.5899,  6.1739, -2.7943,  5.8956, -2.8896]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -1.087676336375964, distance: 1.6534393820222932 entropy 3.2771571577000884
epoch: 6, step: 17
	action: tensor([[-15.8700,  -9.7649,  16.1191,   0.7320,  -8.9686,  12.2611,   6.9720]],
       dtype=torch.float64)
	q_value: tensor([[-12.7225]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.8083035748007377
epoch: 6, step: 18
	action: tensor([[-13.6607, -13.0568,   0.9034,   0.9387, -12.0552,  -9.9672,   7.2924]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 19
	action: tensor([[-13.2138,  -6.5387,  -6.9091,  -6.9137,  -2.0690,   3.1507,  -1.2283]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 20
	action: tensor([[-11.8810,  -8.4239,  19.6586,   9.0170, -13.0832,  -0.8486,   6.0966]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 21
	action: tensor([[-13.6486, -10.0649,   6.7594,  -7.4240,  -2.0101,  -0.8627,  10.5009]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 22
	action: tensor([[-14.2675,  -9.6833,  -3.9020,  12.7435,  -0.7938,   2.2968,   5.5218]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 23
	action: tensor([[-18.3275,  -7.0460,  -0.2966,  -0.2491,  -0.9306,  -0.5745,  -1.8685]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.21308183831317207, distance: 1.2603806981398629 entropy 3.2771571577000884
epoch: 6, step: 24
	action: tensor([[-10.4960,   0.1670,  -1.7020,  -9.0229,  -6.6098,  -7.9867,   4.0318]],
       dtype=torch.float64)
	q_value: tensor([[-6.7768]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.210257400737453
epoch: 6, step: 25
	action: tensor([[-13.6953,  -8.2502,  -2.6879,   3.2706,  -5.9949,  -9.1339,  -0.7873]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 26
	action: tensor([[-25.2719,   1.6401, -17.1161,   2.8490, -15.7724,  -0.3400,   5.2009]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 27
	action: tensor([[-21.0107,   4.4848,   2.9946,   0.4098, -11.6703,  -2.5962,   0.3579]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 28
	action: tensor([[-14.3749,  -7.1532,   8.1599,   1.6382,  -7.2845,  15.9807, -12.8534]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 29
	action: tensor([[ 0.2906, -7.9416,  0.6777, -7.6985,  2.1799,  7.2342,  4.3553]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 30
	action: tensor([[-8.7779,  9.6028,  0.7433,  1.9562,  1.2565, -4.2926, -7.3276]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 31
	action: tensor([[-15.6406, -12.6618, -10.5820,  -7.7107, -11.3438,   3.2598,   8.0979]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 32
	action: tensor([[-13.2202, -12.5440,   2.4303,   3.7525,  -9.5710,  -1.5895,  -1.2336]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 33
	action: tensor([[-6.5724,  3.8733, -2.5066,  3.3056, -2.3208,  4.6948, -5.7775]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 34
	action: tensor([[-14.7957, -13.2585,  -7.3493,  18.5749,  -2.3909,  10.7612,   7.1578]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 35
	action: tensor([[-17.5319,  -1.9673, -10.9391,  11.9858, -11.1708,   9.3578,   9.1776]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 36
	action: tensor([[-16.6853,   0.9004,  -0.6098,   5.3297,  -4.8276,  -7.0492,  -2.5768]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 37
	action: tensor([[-11.9294, -19.2701,   5.8518,   4.2827,   5.4360,   5.2523,   5.1272]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 38
	action: tensor([[-7.6598,  1.2298,  6.0646, -2.3662, -1.4706, -6.8596,  9.3711]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 39
	action: tensor([[-14.8490,  -3.8052,  -8.4651,   8.8769, -10.7073,   7.6940,  16.0503]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 40
	action: tensor([[-9.1018, -1.9508, 14.1271,  1.1090, -3.3603, 20.6809,  0.9646]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 41
	action: tensor([[ -5.1177, -15.5753,  -8.5271,   4.4570,  -5.0587, -15.0737,  -4.6476]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 42
	action: tensor([[-14.8160,  -5.9108,   9.5576,  13.2767,  -8.4940,  -5.6102,  15.3436]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 43
	action: tensor([[-13.9358,  -5.2052,  -2.6020,  -7.5318,   5.6446,  14.5672,   3.2312]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.21138816752628486, distance: 1.016221403651244 entropy 3.2771571577000884
epoch: 6, step: 44
	action: tensor([[-27.4394, -22.7381,   6.9661,  12.9788, -24.5692,  -1.2120,   5.5918]],
       dtype=torch.float64)
	q_value: tensor([[-13.8709]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.796340636596756
epoch: 6, step: 45
	action: tensor([[-10.2986, -19.7760,  -6.6556,   1.8535,  -6.4589,  10.4323,   1.6021]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 46
	action: tensor([[-13.7231,  -8.3621,  -7.8583,   1.0041,  -4.4712,   1.2503,   6.8586]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 47
	action: tensor([[-13.7589, -12.5139,  -3.2342,  -2.9419,  -4.0318,  -1.9057,   3.2742]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 48
	action: tensor([[-19.8062, -12.6210,  -0.6563,   6.2005,  -9.1439,   6.8674,  -1.3284]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.8608807080784842, distance: 1.561046931856153 entropy 3.2771571577000884
epoch: 6, step: 49
	action: tensor([[ -9.4410,   1.7456,  -4.8147,  15.7592,  -8.5231, -21.0338,  -2.9659]],
       dtype=torch.float64)
	q_value: tensor([[-10.7763]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.5963660779606137
epoch: 6, step: 50
	action: tensor([[-11.8259, -11.4601,  -1.9268,   3.7515,   3.0609,   6.9089,   4.2895]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 51
	action: tensor([[ -4.9620,  -8.2951,   8.5898,  -1.3936,   0.0647, -11.5261,  -1.5394]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 52
	action: tensor([[-6.1107, -5.6799, -2.0674,  2.0073, -3.3985, -1.1420,  3.2728]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.0066619779159440284, distance: 1.140526086161818 entropy 3.2771571577000884
epoch: 6, step: 53
	action: tensor([[-14.7326,  -2.5289, -18.1567,  -2.8516,  -2.0755, -11.4059,   0.4185]],
       dtype=torch.float64)
	q_value: tensor([[-10.7932]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.754664135466501
epoch: 6, step: 54
	action: tensor([[-16.8903,  -3.9621,   2.2140,   5.3469,   9.4737,  -7.0350,  13.2238]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 55
	action: tensor([[-10.5839,  -8.8969,   1.4229,   7.9905, -14.4534,  -9.2924,   3.8167]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 56
	action: tensor([[-17.9262,  -1.2245,   1.6758,  -1.4332,  -4.5623,  -8.1666,  -5.4998]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.45683622368786814, distance: 0.843377659762743 entropy 3.2771571577000884
epoch: 6, step: 57
	action: tensor([[-21.4591,  -6.2611,   0.6369,   3.4893, -21.4624,   2.5239,  11.8414]],
       dtype=torch.float64)
	q_value: tensor([[-9.4359]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.4147807469785425
epoch: 6, step: 58
	action: tensor([[ -6.5029, -14.0687,   7.9287,   2.6508, -11.8182,  -3.3327,  -1.5928]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 59
	action: tensor([[-12.3339,  -0.3377,  -1.3217,  -4.2508,  -4.9044,   3.4678,   0.5756]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 60
	action: tensor([[-18.8684,  -4.8372,   6.1135,   0.4342,   1.7216,   4.0092,  -3.6308]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 61
	action: tensor([[-12.0141,  -7.1133,   0.4885,   4.8369,  -8.5516,  12.4419,   6.8310]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -0.7955803521042477, distance: 1.5334129108010022 entropy 3.2771571577000884
epoch: 6, step: 62
	action: tensor([[-17.6767,  -5.4674,  -1.6810,   5.7417,  -9.9326,  -6.4151,   6.3734]],
       dtype=torch.float64)
	q_value: tensor([[-7.8345]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.3593228815126546
epoch: 6, step: 63
	action: tensor([[-12.6335,  -9.6162,  -2.7086,   6.3302, -10.8612,  -9.2867,  -1.8145]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 64
	action: tensor([[-11.9309,  -7.7245,  -8.1096,   1.1587,  -1.7736,   8.6356,   7.8452]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 65
	action: tensor([[-15.9377,  -5.9433,  -1.5115,   9.2386,   1.6752,  16.0994,  -7.0946]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 66
	action: tensor([[-11.4410, -15.9455,   3.2960,  -0.4870,   4.8585,  -6.9878,   1.4028]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 67
	action: tensor([[-15.6793,  -3.4165, -13.8460,   8.5274,  -9.1787,   1.9049,   2.8753]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 68
	action: tensor([[-13.1524,   3.0328,  -1.1741,  -3.9100,  -1.5703,   5.8103,   8.0304]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 69
	action: tensor([[-8.7427, -3.9407,  0.3683, 11.6139, -7.3143, 16.3202, -1.5214]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 70
	action: tensor([[ -8.8379, -11.6658,  -5.9185,  14.6624,   0.6937,   5.2431,  13.9581]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 71
	action: tensor([[ -9.6212, -14.5836,   7.8091,   0.7867,  -9.4849,  -4.2812,   1.1593]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 72
	action: tensor([[ -6.7607, -11.3129,  -0.4090,   4.3437,  -5.0871,  -0.0917,  10.1106]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 73
	action: tensor([[-18.6038,  -8.1756,  -3.7083,  16.7874,  -4.4175,  -3.3720,   5.4542]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 74
	action: tensor([[-10.6978,  -4.4331,  -0.6584,  -0.9185,   1.1107,  14.8383,  17.0710]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 75
	action: tensor([[-7.0155, -7.2162, -2.4924, -0.0405, -5.6291,  0.7142,  2.8784]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -1.3506112402711885, distance: 1.7544746498803958 entropy 3.2771571577000884
epoch: 6, step: 76
	action: tensor([[-22.2052,  -7.8003,  -7.8719, -11.7112, -17.4511, -18.3269,  -3.8104]],
       dtype=torch.float64)
	q_value: tensor([[-9.3275]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.630555407611024
epoch: 6, step: 77
	action: tensor([[-9.9576, -0.5727,  3.0802, -2.0277, -3.2105,  3.7265,  0.6577]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 78
	action: tensor([[-10.8918, -16.5105,   1.4362,  10.5634,  -3.2202,   6.3140,   1.6418]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 79
	action: tensor([[-11.4859,  -7.3715,   1.6138,   4.5715,  -2.0275,  -6.5093,  -3.2768]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.06340194355113293, distance: 1.1074734395970784 entropy 3.2771571577000884
epoch: 6, step: 80
	action: tensor([[-22.6941, -23.7886,   0.2242,   6.9174,  -0.7075,  -0.5997,   8.0194]],
       dtype=torch.float64)
	q_value: tensor([[-9.6622]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.6775279833583348
epoch: 6, step: 81
	action: tensor([[-16.6763,   0.1039,  -0.7714,  11.8277,  -0.9213,  -6.7953,   4.7983]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 82
	action: tensor([[-18.8417,  -3.5811,   3.8852,   6.9992,  -1.0309,   9.9335,  10.0259]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 83
	action: tensor([[-12.7041,  -4.9364,  -3.0059,   4.4396, -16.6828,  -1.2527,  10.5735]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 84
	action: tensor([[-9.1772, -3.3142,  2.9746,  7.5367, -1.5092,  9.8111,  8.7847]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 85
	action: tensor([[-12.8569,  -6.4432, -10.3974,   6.6268,   3.0183,  -2.5012,  -2.2526]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 86
	action: tensor([[-18.9893,  -7.6159,  12.4036,  13.7839,  -2.8921,   2.0162,  -1.4573]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 87
	action: tensor([[-10.9330, -13.5039,   8.0361,   7.1431,  -8.8147,  -5.9688,  11.9300]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 88
	action: tensor([[-21.3200,  -3.6102,   1.5543,   4.5864,  -2.7221,   8.6545,  -1.8839]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 89
	action: tensor([[-15.4799,  -7.3909,   1.1703,  -1.9058,  -2.2365,  -5.0025,   3.3099]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 90
	action: tensor([[-10.1657,  -3.2792,  -4.1364,   4.7464,  -0.4123,   6.7824,   5.0957]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 91
	action: tensor([[ -6.9132, -11.2068,   3.5470, -13.8053,  -3.2729,  -2.0257,  14.6203]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.3342070593912121, distance: 0.9337406935185472 entropy 3.2771571577000884
epoch: 6, step: 92
	action: tensor([[-30.4791, -12.7607,   4.5042,   7.1717,  -7.4099,  -3.8395,  12.6596]],
       dtype=torch.float64)
	q_value: tensor([[-12.9924]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.8389781204952835
epoch: 6, step: 93
	action: tensor([[-14.1299,   6.5346,  -1.4945,  -4.5713,   4.8503,  16.0676,   7.6667]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 94
	action: tensor([[-9.3696, -3.3304,  0.2227, 16.9525, -6.2978,  5.1278, 10.4538]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 95
	action: tensor([[ -8.6235,  -0.5657,   3.6258,  17.4949, -12.5512,  -9.5772,  11.8845]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 96
	action: tensor([[-7.3247,  1.5023,  8.3699, -4.7661, -8.0789,  1.7247, -5.0194]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 97
	action: tensor([[ -4.6026,  -6.8155,   7.1122, -10.2331,  -2.2680,   1.5145,  11.5142]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 98
	action: tensor([[-15.2612,   5.7723, -14.3265,   8.3885,  -3.6590,   7.9135,  -6.3938]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 99
	action: tensor([[-8.6918, -5.0953,  7.6074, -3.2560, -7.3977, -0.3375,  5.7456]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 100
	action: tensor([[-18.4875, -19.7164, -13.0256,   9.0630, -12.6083,   1.8279,   3.3574]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 101
	action: tensor([[-10.0657,  -7.9148,  -7.8126,  -1.2271,  -6.9031,   6.5831,  -2.9365]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 102
	action: tensor([[-8.7179, -8.7548,  0.6885, -0.3478, -5.5378,  5.6517,  6.8187]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 103
	action: tensor([[-13.2742,  -5.7854, -10.5207,   2.7373,  -4.6584,  -0.5801,  18.3239]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 104
	action: tensor([[-19.0401,  -0.7006,   1.8196,  10.7544,  -1.2716,  14.3841,  18.2857]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.12036000118466361, distance: 1.0732704640276536 entropy 3.2771571577000884
epoch: 6, step: 105
	action: tensor([[-9.8492, -6.2858, -0.9142, -3.6440, -3.3008, 29.4605, 17.2248]],
       dtype=torch.float64)
	q_value: tensor([[-8.3493]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.3948036108915898
epoch: 6, step: 106
	action: tensor([[ -1.7733, -16.6388, -11.5396,   0.7677,  -7.6144,   7.1926,  -3.0635]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 107
	action: tensor([[-16.7991,   3.1616,   2.7024,   8.2062,  -7.9438,   7.3962,  -9.8276]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 108
	action: tensor([[-14.9069, -10.0628,   4.0522,  14.4138,  -6.0029,   0.5669,   0.5396]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 109
	action: tensor([[-18.5292,  -9.0116,   0.8250,   8.8095,  -8.2945,  14.2868,   0.4873]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 110
	action: tensor([[-12.3293,  -6.3727,  -7.5010,  10.7698,  -2.3369,  -3.3734,  11.0707]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 111
	action: tensor([[-21.3359,  -5.6929,   2.7180,  -1.8343,  -4.7385,  -5.0438,   2.3314]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 112
	action: tensor([[-9.5335, -5.5040,  0.5962, -7.1914, -3.8412,  3.3240, -3.3738]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 113
	action: tensor([[ -7.2854, -20.3997,   1.8381, -12.1551, -12.0606, -12.0340,   3.2047]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 114
	action: tensor([[ -8.3440,  -0.7629,  -0.9888,   6.1032,   0.5432,  -4.4967, -15.3017]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 115
	action: tensor([[-13.8426, -13.0499,   5.1435,   6.9089,  -0.4313,  -6.1084, -12.2109]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: -1.8042659888294517, distance: 1.9163123373911939 entropy 3.2771571577000884
epoch: 6, step: 116
	action: tensor([[-6.6883, -4.7172,  1.4482,  6.9581, -8.2265,  2.2676, 16.2415]],
       dtype=torch.float64)
	q_value: tensor([[-6.1244]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.1694098707025513
epoch: 6, step: 117
	action: tensor([[-18.6715,  -7.0659, -12.2496,  14.9435,  -5.1376,  -8.6338,   1.3422]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 118
	action: tensor([[-18.2341,  -2.5497, -11.1990,   2.4393,  -9.2690,   6.6963,   3.5903]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 119
	action: tensor([[ -6.6722,  -6.1959, -16.1686,  18.4951,  -8.5074,   2.3081,  -8.7651]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 120
	action: tensor([[ -8.1693, -12.5363,  -0.5623,  -3.5575,  -4.3010, -18.9619,  11.5245]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 121
	action: tensor([[-20.4382, -14.1068,   5.6419,  -9.1758,   0.5405,  16.2136,  10.9622]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 122
	action: tensor([[-11.3027,  -3.4427,  -3.6156,   3.2627,  -6.6704,  -8.8066,   6.4069]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 123
	action: tensor([[ -9.2710,  -4.5052,  -4.9280, -15.2304,  -0.8779,  -8.7775,   2.9299]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 124
	action: tensor([[-12.7770,  -6.0379,   2.7141,   3.4095,   5.3976,  11.8233,   1.1742]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 125
	action: tensor([[-0.1726, -2.9933, -6.2861,  9.6968, -1.4180, 10.1897,  1.0832]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 126
	action: tensor([[-13.0039,   1.3340,   7.5183,   0.0310,  -3.0039,  -4.6768,   2.0223]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
epoch: 6, step: 127
	action: tensor([[-12.9071, -15.5437,  -1.0908,   6.7075,  -8.1514,  -7.6753,   0.6729]],
       dtype=torch.float64)
	q_value: tensor([[-9.7044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.2771571577000884
LOSS epoch 6 actor 402.63434522063375 critic 1605.797957094564
epoch: 7, step: 0
	action: tensor([[-9.2549,  0.2475, -0.7840, 11.7765,  1.8470,  3.8461,  7.4172]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 1
	action: tensor([[-18.6052, -20.8156,  -1.1274,  -1.1712,   6.7949,   4.0250,   5.7582]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 2
	action: tensor([[-20.0045, -10.4710,   4.3808,   3.8785,  -8.3742,  -2.8876,   9.6860]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 3
	action: tensor([[-19.7282, -10.5642,  -0.9076,  14.7091, -14.1690,   1.0767,   0.6241]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 4
	action: tensor([[-24.2322,   3.2330,  15.4378,  14.5592,  -6.3089,   1.2272,  -3.6406]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 5
	action: tensor([[-21.9908, -16.7786,  -1.9282,   4.3230, -12.0319,   5.0412,   4.5810]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 6
	action: tensor([[-19.5599,  -4.4004,   0.3623,  -3.0632,  -5.1124,  25.4158,   9.4274]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 7
	action: tensor([[-13.7574,  -1.4496,  -8.6937,   6.6039,  12.3031,  -1.2138,  -2.2999]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 8
	action: tensor([[-19.6071,  -7.4807,   6.9133,   3.7246,   5.8630,  13.8909,  -2.9364]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 9
	action: tensor([[ -5.8750,  -4.3668,   0.8482, -14.0180, -20.4389,   1.0898,  13.2242]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 10
	action: tensor([[-18.2641, -17.5493,  -6.7695,  12.4271, -12.2621,   2.7861,  -5.2772]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 11
	action: tensor([[-24.7128, -21.4311,  -3.0318,  17.0890, -19.3554,  18.2523,  -0.9397]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 12
	action: tensor([[-15.0809,   0.0673,   5.8731,  12.7865,   5.5024, -10.7526,  -1.8502]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 13
	action: tensor([[-11.6293,  -9.1325,  18.7650,  13.4386,   4.1692,   0.9450,   4.4710]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 14
	action: tensor([[ -8.7723,  -8.5348, -11.9214,  -1.2559, -12.3705,  14.1927,  10.3073]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 15
	action: tensor([[-29.0080,  -5.3380, -15.7358,  11.4272,  -2.2456,  -2.1032,   6.0093]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 16
	action: tensor([[ -4.4131,  -1.5179,   2.8369,   0.1243,   2.4536, -14.4421,  -3.4940]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 17
	action: tensor([[-12.7343,  -3.6308,   5.0408,   9.0195,  -8.8169,   2.1338,   8.1601]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 18
	action: tensor([[ -6.1044, -11.3164,   1.7751,  -4.5415,  -2.0408,  -1.5730,  10.2777]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 19
	action: tensor([[-27.6345, -14.0531,  -7.9675,  -0.8915,  -4.4855,  12.6866,   8.6084]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 20
	action: tensor([[ -9.8060, -10.6783,   1.4965,   1.5990, -13.3838,   4.0428,   4.8051]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 21
	action: tensor([[-13.1166,  -9.0699,   6.8546,  -6.1614,  -3.1736,  -6.3299,  -9.2191]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 22
	action: tensor([[-17.0793, -11.3364,   6.8874,   1.2009,  -5.7317,  14.5798,  10.6585]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 23
	action: tensor([[-15.2045,  -4.3624,   1.2923,  -3.9913,  -1.5041, -23.8815, -16.3200]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 24
	action: tensor([[-18.5428,  -6.5136,  -0.6273,  -5.7056,  -7.3099, -15.3193,  17.8909]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 25
	action: tensor([[-41.8959, -22.5210,  -4.0239,   5.9145,  -3.4374,  -3.4858,  -8.3755]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 26
	action: tensor([[ -8.2148, -20.0866,  12.7301,  -1.4640,  -7.7516,  10.1807,  -6.0265]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 27
	action: tensor([[-23.7022,  -9.9882,  14.4518,   5.1907,  -7.8097, -12.7441,  12.0427]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 28
	action: tensor([[-19.3023, -12.1701,   2.7503,  -5.8938, -18.7090,   3.5189,  -3.2359]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 29
	action: tensor([[-20.3013,   3.1808,   7.4448,   6.2476,  -4.9730,   3.9460,  -8.6933]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 30
	action: tensor([[-12.6838,  -3.4124, -11.0500,   5.0749,  -3.3709,   2.2795,   5.5001]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 31
	action: tensor([[-15.2132,  -8.8904,  -4.2214,  -5.0166, -22.2854,   9.5771,   9.7237]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 32
	action: tensor([[ -3.8450, -19.4019,  -0.4986,  -0.4374,  -9.3453,   5.5296,   9.7459]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 33
	action: tensor([[-22.8087, -18.8185,   3.1122,  27.0512, -10.3924,  -4.1674, -14.0586]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 34
	action: tensor([[-23.7169,   3.4424, -19.9018,   9.0151,  -4.5518,  -6.4926,  -5.7776]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 35
	action: tensor([[-21.2352, -18.8116,   7.9759,   3.3792,  11.9562, -14.4437,  -3.5131]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 36
	action: tensor([[-25.0033,  -7.6764, -14.0031,  -5.2626,   0.2330,  26.4751,  -3.4587]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 37
	action: tensor([[ -6.0305, -11.0901,   1.4387,  12.7105, -16.7117,  -4.4328,   7.6278]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 38
	action: tensor([[-22.5165, -12.6577, -15.1052,  19.4161,  -4.9185,  18.6524, -13.0358]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 39
	action: tensor([[-13.0102, -14.8615,   3.3508,  24.8598,   3.2274, -18.2450,   1.6885]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 40
	action: tensor([[-20.7787,  -3.9504,  -3.4397,   4.8517,   0.3476,  -4.2892,  17.2837]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 41
	action: tensor([[-1.4081e+01, -1.2588e+01, -5.7821e-03,  1.5592e+01, -1.2740e+01,
         -2.4484e+00, -5.3018e-01]], dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 42
	action: tensor([[-20.5327, -13.3025,  17.0134,  27.5187,  -2.2211, -16.2477,   5.8151]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 43
	action: tensor([[-14.7189,  -5.9825, -13.9847,  -7.3042, -11.4522, -14.2349,   5.8710]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 44
	action: tensor([[-16.6703, -21.7194,   2.3775,   0.0222,  -0.6781, -10.0691,  -2.5403]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 45
	action: tensor([[-12.9655,  -7.0800,  11.0487,  -9.8622,  -3.4551,   2.6328,   8.7597]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 46
	action: tensor([[-20.2172,  -9.3107,  -1.8025,  -7.1909, -10.2858,   1.0672,  13.5382]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 47
	action: tensor([[-12.8796, -22.5516,   9.7203,   5.8555,   7.3767,  22.9877,   1.0159]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 48
	action: tensor([[-28.6603,  -0.3941,   1.1444,  -3.1553, -13.3841,   1.0983,  14.6323]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 49
	action: tensor([[-2.9177, -8.4807,  9.1643,  6.0779, -6.0373,  8.9646, -7.4719]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 50
	action: tensor([[-30.3862,  -9.8367,   0.7685,  -1.6978, -10.7474,  13.7567,  10.2231]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 51
	action: tensor([[-17.2235,  -0.5034,   3.7026,   3.9059,  -3.9277,  20.2138,   6.6673]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 52
	action: tensor([[-21.5175,  10.5360,  -5.5408,   5.3925,   0.4497,  -9.7263,   2.7420]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 53
	action: tensor([[-21.2271, -15.8519,   6.3909,  15.4617, -17.4292,   4.6720,   1.0416]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 54
	action: tensor([[ -6.6315,  -7.8935,  -3.0559,  -4.3842,  -3.0401, -12.7675,  -0.5167]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 55
	action: tensor([[-13.7169, -14.7443, -12.2207,  -1.0563,  -8.2502,  23.4712,   3.9165]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 56
	action: tensor([[-14.9912,   1.1435,   7.3260,  -2.4074,   2.8645, -12.4943,   6.2058]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 57
	action: tensor([[-14.0441,  -2.2323,  -2.8743,  14.2342,   3.2258,  -1.3623,  20.9096]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 58
	action: tensor([[-13.6820, -10.8126,   0.0447,   0.7896,  -6.7736,  -1.2582,   1.4574]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 59
	action: tensor([[ -2.2606, -18.4560,  -7.1917,  -7.2709, -15.5616,   4.7684,  -0.6557]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 60
	action: tensor([[-17.3124,  -1.3146,  -6.2524,  -8.7364,  -4.7698,   7.0713,  16.6489]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 61
	action: tensor([[-22.3455,  -3.9362,   5.4287,   6.2963,  -9.5778,   2.8630,  21.5787]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 62
	action: tensor([[-15.8322,  -5.0761,  11.8363,   9.9251, -13.9092, -12.1324,  -4.0546]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 63
	action: tensor([[ -7.8077, -18.0049,   4.8433,  16.3773,   1.5831,  -8.3733,   1.7800]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 64
	action: tensor([[-18.3347,  -9.7048,  -7.6466,  -0.6575,  -3.5988,  -3.2754,  15.3243]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 65
	action: tensor([[-18.8525, -13.0365, -13.5860,  11.6751,  -9.4705,   6.1954, -17.8041]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	reward: 0.0731469722897421, distance: 1.1016969059701665 entropy 3.546012052759555
epoch: 7, step: 66
	action: tensor([[-26.5438,  -4.7636,  -6.3032,   1.5897, -11.6477,  19.6852,  -4.5507]],
       dtype=torch.float64)
	q_value: tensor([[-12.8251]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.712674215050383
epoch: 7, step: 67
	action: tensor([[-30.0893,   8.3079,  -3.6553, -11.0451, -21.6621, -11.6338,  10.2467]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 68
	action: tensor([[-13.9594,  -2.2914,   9.3020,   5.3122,  -0.1304,   8.0604,   5.5873]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 69
	action: tensor([[-17.6338,  -4.5179,  -1.7901,   1.6389,  -0.8196,  -4.1582,   6.6891]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 70
	action: tensor([[ -6.3093, -10.7279, -12.8639,  -9.9303,  -6.0751, -13.4459,  -6.6575]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 71
	action: tensor([[  4.3759, -11.4144,  -9.4248,  -2.6191,  -9.4903,  -8.0920,   4.2608]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 72
	action: tensor([[-20.5599, -18.9482,   5.0120,   4.7613, -18.4696,  11.1735,  -0.3150]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 73
	action: tensor([[-21.9626,   3.4452,  -3.2596,  12.6108,  -3.7429,  -4.2973,  -2.6696]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 74
	action: tensor([[-18.2138,  -2.1477,  -0.2470,  -8.4161,  -9.3283,   3.1913,  10.5160]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 75
	action: tensor([[-21.9761, -18.3632,  -5.5478,   9.9378, -15.1406,  -3.0133,   3.5643]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 76
	action: tensor([[ -9.3721,  -3.5011,   3.8653,   3.1790, -18.7940,  11.1911,   1.9988]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 77
	action: tensor([[-10.3757,  -8.1748,  -3.2158,   6.1640, -11.0618,  -7.3301,  10.9887]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 78
	action: tensor([[-18.9849,  -3.9793,   2.8323,   8.0351, -10.1521, -14.0434, -13.5735]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 79
	action: tensor([[-14.2911,   9.1741,  -6.0062,  -9.3527, -13.2792,  -1.6669,  -7.4974]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 80
	action: tensor([[-18.2506,   0.6441,   0.1524,  -2.3899,  -4.0891,   2.0237,   8.1967]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 81
	action: tensor([[-2.4578e+01, -1.0361e+00, -8.8473e+00,  4.7498e+00, -9.8280e+00,
          8.8262e+00,  2.0318e-04]], dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 82
	action: tensor([[-14.6115, -22.6860,  12.2709,  16.3508,  -3.2989,   7.6131,  17.3261]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 83
	action: tensor([[-6.8611, -5.3956,  2.4477, -8.0511, -7.7575, -2.5747,  8.8709]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 84
	action: tensor([[-20.8333,  -1.6532,  -1.2504,  18.7519,  -1.9134,  10.8548,  32.5311]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 85
	action: tensor([[ -8.1812,  -0.7508,   3.0375,   2.3942, -16.0426,   2.1093,  -6.5725]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 86
	action: tensor([[-25.0972,  -1.4280,  -9.5527,   1.5708,  -3.1615,  -8.8748,  -5.7437]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 87
	action: tensor([[-15.5542,  -6.5402,  -0.7391,  -4.6102,   6.9743, -11.7343, -13.4963]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 88
	action: tensor([[-24.6132, -12.1159,  -4.9429,  -7.8668,  -0.7930, -10.7497,  12.6660]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 89
	action: tensor([[ -4.3854, -13.6966,  -2.2079,   2.9846,  -2.7602,  -1.3161,  11.0504]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 90
	action: tensor([[ -6.8240,  -9.7070,   2.2643,   9.7981,  -7.6580, -20.8785,  -0.1625]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 91
	action: tensor([[-13.7710,  -4.7055,  -0.8722,  -4.5801,  -7.4750,  -1.6564,   0.3307]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 92
	action: tensor([[ -6.9014,  -7.9279, -15.0788,   7.2075, -16.6956,   5.9689,  -1.3264]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 93
	action: tensor([[-27.8800, -10.8015,  -7.6233,  22.2202, -11.7560,  -4.2086,   8.7737]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 94
	action: tensor([[-18.2530,  -9.7864,  -6.1949,  13.7747,  -4.7375,  14.4451,  10.3625]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 95
	action: tensor([[ -6.9499,  -9.9473,  -9.5390,  -7.2295, -15.7123,   7.6643,  14.7055]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 96
	action: tensor([[-19.0818,  -3.6378,  -6.9672,   7.8196, -11.8346,   5.1868,  -1.9955]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 97
	action: tensor([[-23.3834,  -8.7023,   9.0352,  -2.7176,   2.5318,  -1.2539,  18.1805]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 98
	action: tensor([[-0.3097, -8.9895,  4.8471, -0.8677,  3.3949,  1.9638,  0.0227]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 99
	action: tensor([[-16.2624,   4.5494, -14.9755,   7.3995,   3.3096,   2.7286,   9.8790]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 100
	action: tensor([[-21.4273,  -8.7815,  -4.5986,   9.6901, -18.3767,   1.4800,   6.7341]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 101
	action: tensor([[-24.0005,  -4.7355,  -6.5405,  11.1687,  -8.5498,   4.9587,  -1.7400]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 102
	action: tensor([[-11.7559,  -8.7139, -13.2538,   3.4982,   0.6579,  -2.0997,   7.3672]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 103
	action: tensor([[ -9.6645,  -1.7877,  -3.9454, -11.6794,   1.4247,  11.6396,  16.1397]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 104
	action: tensor([[-10.2840, -18.0631,  -5.5503,  -3.4946, -15.4112,  11.5975,  20.0733]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 105
	action: tensor([[ -6.9020,  -8.5649,  -4.6537,  -8.8415, -13.0034,  -5.4606,  10.0801]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 106
	action: tensor([[ -7.2833, -28.8222,   5.3884, -10.9313,  -9.3063,  -2.4883,  13.2322]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 107
	action: tensor([[-9.8082, -1.7437, -6.8504, -3.6001, -0.6377, 16.7271,  3.5133]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 108
	action: tensor([[-10.0255, -16.4955,  -1.1944,   1.3923,  -2.6416, -14.5163,  15.3780]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 109
	action: tensor([[-17.2871, -10.8118,  -1.7344,  10.4461, -21.7677, -22.3708,   9.0860]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 110
	action: tensor([[ -6.2768,  14.9779, -10.9186,   6.8822,  -8.3255,   9.5890,  14.2474]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 111
	action: tensor([[-10.4639,  13.8143,  -2.0102,   2.9052,  -6.9943,   5.5457,  17.6370]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 112
	action: tensor([[-9.3861,  3.6291,  2.8709,  7.8436, -7.5245, -2.0358, -8.7652]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
epoch: 7, step: 113
	action: tensor([[-17.4169, -13.6221,  -5.1371,   8.1144,  -1.8668,  -9.8657,  11.8027]],
       dtype=torch.float64)
	q_value: tensor([[-15.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)
	COLLISION
	reward: -50, distance: 0 entropy 3.546012052759555
